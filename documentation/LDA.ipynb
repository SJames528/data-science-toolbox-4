{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas\n",
    "import pickle\n",
    "import math\n",
    "import numpy\n",
    "import seaborn\n",
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "pyLDAvis.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "from urllib.request import urlretrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.random.seed(0xC0FFEE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\n",
    "    'full_lda_model.pickle',\n",
    "    'full_tf.pickle',\n",
    "    'full_tf_vectorizer.pickle',\n",
    "    'full-dataset.csv.gz',\n",
    "]\n",
    "\n",
    "base_url = 'https://daniel.wilshirejones.com/private-uUX6IzfsRYLNiti4ZFmgv6U3dFInnq37r5YSQs46iejeB96q0MAy9Ko7hkgo/'\n",
    "destination_directory = '../data/'\n",
    "\n",
    "for file in files:\n",
    "    url = base_url + file\n",
    "    destination = destination_directory + file\n",
    "    print(\"Downloading '{}'' to location '{}'\".format(url, destination))\n",
    "    urlretrieve(url, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimal_dataset = pandas.read_csv(\"../data/dataset.csv.gz\", header=None, names=['repo', 'language', 'documents'])\n",
    "minimal_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_language_percentages(group):\n",
    "    total_python_length = 0\n",
    "    total_r_length = 0\n",
    "    total_javascript_length = 0\n",
    "    \n",
    "    for index, repo, language, document in group.itertuples():\n",
    "        if language == 'python':\n",
    "            total_python_length += len(document)\n",
    "            \n",
    "        if language == 'javascript':\n",
    "            total_javascript_length += len(document)\n",
    "            \n",
    "        if language == 'r':\n",
    "            total_r_length += len(document)\n",
    "            \n",
    "    total_length = total_python_length + total_r_length + total_javascript_length\n",
    "            \n",
    "    return pandas.Series([\n",
    "        total_python_length/total_length,\n",
    "        total_r_length/total_length,\n",
    "        total_javascript_length/total_length,\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_importance_per_topic(model, tf_vectorizer):\n",
    "    feature_map = dict(enumerate(tf_vectorizer.get_feature_names()))\n",
    "    \n",
    "    word_importance_per_topic = []\n",
    "\n",
    "    for topic_components in model.components_:\n",
    "        word_importance = [\n",
    "            (feature_map[feature_index], feature_importance) \n",
    "            for feature_index, feature_importance in enumerate(topic_components)\n",
    "        ]\n",
    "        word_importance = sorted(word_importance, key=lambda tup: tup[1], reverse=True)\n",
    "        word_importance_per_topic.append(word_importance)\n",
    "        \n",
    "    return word_importance_per_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def jaccard_index(a, b):\n",
    "    a = set(a)\n",
    "    b = set(b)\n",
    "    \n",
    "    num_shared = float(len(a & b))\n",
    "    num_total = float(len(a | b))\n",
    "    \n",
    "    return num_shared/num_total\n",
    "jaccard_indexes = pandas.DataFrame(\n",
    "    numpy.array([\n",
    "        [\n",
    "            jaccard_index(javascript_keywords, most_importance_topic_1_keywords)/len(javascript_keywords),\n",
    "            jaccard_index(javascript_keywords, most_importance_topic_2_keywords)/len(javascript_keywords),\n",
    "            jaccard_index(javascript_keywords, most_importance_topic_3_keywords)/len(javascript_keywords),\n",
    "            jaccard_index(javascript_keywords, most_importance_topic_4_keywords)/len(javascript_keywords)\n",
    "        ],\n",
    "        [\n",
    "            jaccard_index(r_keywords, most_importance_topic_1_keywords)/len(r_keywords),\n",
    "            jaccard_index(r_keywords, most_importance_topic_2_keywords)/len(r_keywords),\n",
    "            jaccard_index(r_keywords, most_importance_topic_3_keywords)/len(r_keywords),\n",
    "            jaccard_index(r_keywords, most_importance_topic_4_keywords)/len(r_keywords),\n",
    "        ],\n",
    "        [\n",
    "            jaccard_index(python_keywords, most_importance_topic_1_keywords)/len(python_keywords),\n",
    "            jaccard_index(python_keywords, most_importance_topic_2_keywords)/len(python_keywords),\n",
    "            jaccard_index(python_keywords, most_importance_topic_3_keywords)/len(python_keywords),\n",
    "            jaccard_index(python_keywords, most_importance_topic_4_keywords)/len(python_keywords),\n",
    "        ],\n",
    "    ]),\n",
    "    columns=['Topic 1', 'Topic 2', 'Topic 3', 'Topic 4'],\n",
    "    index=['Javascript', 'R', 'Python']\n",
    ")\n",
    "\n",
    "hm = seaborn.heatmap(\n",
    "    jaccard_indexes,\n",
    "    cmap='Blues',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "jaccard_indexes = pandas.DataFrame(\n",
    "    numpy.array([\n",
    "        [\n",
    "            jaccard_index(javascript_keywords, most_importance_topic_1_keywords)/len(javascript_keywords),\n",
    "            jaccard_index(javascript_keywords, most_importance_topic_2_keywords)/len(javascript_keywords),\n",
    "            jaccard_index(javascript_keywords, most_importance_topic_3_keywords)/len(javascript_keywords),\n",
    "            jaccard_index(javascript_keywords, most_importance_topic_4_keywords)/len(javascript_keywords)\n",
    "        ],\n",
    "        [\n",
    "            jaccard_index(r_keywords, most_importance_topic_1_keywords)/len(r_keywords),\n",
    "            jaccard_index(r_keywords, most_importance_topic_2_keywords)/len(r_keywords),\n",
    "            jaccard_index(r_keywords, most_importance_topic_3_keywords)/len(r_keywords),\n",
    "            jaccard_index(r_keywords, most_importance_topic_4_keywords)/len(r_keywords),\n",
    "        ],\n",
    "        [\n",
    "            jaccard_index(python_keywords, most_importance_topic_1_keywords)/len(python_keywords),\n",
    "            jaccard_index(python_keywords, most_importance_topic_2_keywords)/len(python_keywords),\n",
    "            jaccard_index(python_keywords, most_importance_topic_3_keywords)/len(python_keywords),\n",
    "            jaccard_index(python_keywords, most_importance_topic_4_keywords)/len(python_keywords),\n",
    "        ],\n",
    "    ]),\n",
    "    columns=['Topic 1', 'Topic 2', 'Topic 3', 'Topic 4'],\n",
    "    index=['Javascript', 'R', 'Python']\n",
    ")\n",
    "\n",
    "hm = seaborn.heatmap(\n",
    "    jaccard_indexes,\n",
    "    cmap='Blues',"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
