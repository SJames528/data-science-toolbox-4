{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modelling on Program Source Code\n",
    "---\n",
    "By Kishalay Banerjee, Dan Jones and Sam Harding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # 0y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import pickle\n",
    "import math\n",
    "import numpy\n",
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "pyLDAvis.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "from urllib.request import urlretrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.random.seed(0xD00D5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "\n",
    "There are a number of files which are too large to store on GitHub. These are hosted on our server, and can be downloaded by running the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 'https://daniel.wilshirejones.com/private-uUX6IzfsRYLNiti4ZFmgv6U3dFInnq37r5YSQs46iejeB96q0MAy9Ko7hkgo/full_lda_model.pickle'' to location '../data/full_lda_model.pickle'\n",
      "Downloading 'https://daniel.wilshirejones.com/private-uUX6IzfsRYLNiti4ZFmgv6U3dFInnq37r5YSQs46iejeB96q0MAy9Ko7hkgo/full_tf.pickle'' to location '../data/full_tf.pickle'\n",
      "Downloading 'https://daniel.wilshirejones.com/private-uUX6IzfsRYLNiti4ZFmgv6U3dFInnq37r5YSQs46iejeB96q0MAy9Ko7hkgo/full_tf_vectorizer.pickle'' to location '../data/full_tf_vectorizer.pickle'\n",
      "Downloading 'https://daniel.wilshirejones.com/private-uUX6IzfsRYLNiti4ZFmgv6U3dFInnq37r5YSQs46iejeB96q0MAy9Ko7hkgo/full-dataset.csv.gz'' to location '../data/full-dataset.csv.gz'\n"
     ]
    }
   ],
   "source": [
    "files = [\n",
    "    'full_lda_model.pickle',\n",
    "    'full_tf.pickle',\n",
    "    'full_tf_vectorizer.pickle',\n",
    "    'full-dataset.csv.gz',\n",
    "]\n",
    "\n",
    "base_url = 'https://daniel.wilshirejones.com/private-uUX6IzfsRYLNiti4ZFmgv6U3dFInnq37r5YSQs46iejeB96q0MAy9Ko7hkgo/'\n",
    "destination_directory = '../data/'\n",
    "\n",
    "for file in files:\n",
    "    url = base_url + file\n",
    "    destination = destination_directory + file\n",
    "    print(\"Downloading '{}'' to location '{}'\".format(url, destination))\n",
    "    urlretrieve(url, destination)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating the Dataset\n",
    "\n",
    "TODO: Import dataset.py and explain how it's used + what it does.\n",
    "\n",
    "TODO: Add Sam's scrub function in here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>language</th>\n",
       "      <th>documents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28457823</td>\n",
       "      <td>javascript</td>\n",
       "      <td>b\"module.exports = {\\n  plugins: [\\n    requir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28457823</td>\n",
       "      <td>javascript</td>\n",
       "      <td>b\"// The path where to mount the REST API app\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28457823</td>\n",
       "      <td>javascript</td>\n",
       "      <td>b\"import { Observable } from 'rx';\\nimport deb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28457823</td>\n",
       "      <td>javascript</td>\n",
       "      <td>b\"import { Observable } from 'rx';\\n// import ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28457823</td>\n",
       "      <td>javascript</td>\n",
       "      <td>b\"import { Observable } from 'rx';\\n\\nmodule.e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       repo    language                                          documents\n",
       "0  28457823  javascript  b\"module.exports = {\\n  plugins: [\\n    requir...\n",
       "1  28457823  javascript  b\"// The path where to mount the REST API app\\...\n",
       "2  28457823  javascript  b\"import { Observable } from 'rx';\\nimport deb...\n",
       "3  28457823  javascript  b\"import { Observable } from 'rx';\\n// import ...\n",
       "4  28457823  javascript  b\"import { Observable } from 'rx';\\n\\nmodule.e..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minimal_dataset = pandas.read_csv(\"../data/dataset.csv.gz\", header=None, names=['repo', 'language', 'documents'])\n",
    "minimal_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>language</th>\n",
       "      <th>documents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28457823</td>\n",
       "      <td>javascript</td>\n",
       "      <td>b\"module.exports = {\\n  plugins: [\\n    requir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28457823</td>\n",
       "      <td>javascript</td>\n",
       "      <td>b\"// The path where to mount the REST API app\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28457823</td>\n",
       "      <td>javascript</td>\n",
       "      <td>b\"import { Observable } from 'rx';\\nimport deb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28457823</td>\n",
       "      <td>javascript</td>\n",
       "      <td>b\"import { Observable } from 'rx';\\n// import ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28457823</td>\n",
       "      <td>javascript</td>\n",
       "      <td>b\"import { Observable } from 'rx';\\n\\nmodule.e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       repo    language                                          documents\n",
       "0  28457823  javascript  b\"module.exports = {\\n  plugins: [\\n    requir...\n",
       "1  28457823  javascript  b\"// The path where to mount the REST API app\\...\n",
       "2  28457823  javascript  b\"import { Observable } from 'rx';\\nimport deb...\n",
       "3  28457823  javascript  b\"import { Observable } from 'rx';\\n// import ...\n",
       "4  28457823  javascript  b\"import { Observable } from 'rx';\\n\\nmodule.e..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_dataset = pandas.read_csv(\"../data/full-dataset.csv.gz\", header=None, names=['repo', 'language',  'topics', 'documents'])\n",
    "\n",
    "# Remove Github 'topics' since we don't use them in this analysis\n",
    "full_dataset = full_dataset.drop(columns='topics')\n",
    "\n",
    "full_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modelling on Individual Source Files\n",
    "\n",
    "Basically done, just need to copy it over. Maybe run on the bigger dataset?\n",
    "\n",
    "TODO:\n",
    "  - Copy work from documentation/daniel-jones.ipynb\n",
    "  - Add visualisation with pyldavis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our purposes, common words are important and rare words aren't. So we shouldn't use tf-idf as a metric, bag-of-words makes more sense. (TODO: Maybe: \"Similarly, filter out words that don't occur very often\").\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = minimal_dataset['documents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_vectorizer = CountVectorizer(stop_words=None)\n",
    "tf = tf_vectorizer.fit_transform(documents)\n",
    "\n",
    "with open('../data/minimal_lda_tf.pickle', 'wb') as f:\n",
    "    pickle.dump(tf, f)\n",
    "    \n",
    "with open('../data/minimal_lda_tf_vectorizer.pickle', 'wb') as f:\n",
    "    pickle.dump(tf_vectorizer, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have four programming languages, try to use LDA to determine these four programming languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_languages = 4\n",
    "\n",
    "lda = LatentDirichletAllocation(n_topics=number_of_languages,  n_jobs=1)\n",
    "model = lda.fit(tf)\n",
    "\n",
    "with open('../data/minimal_lda_model.pickle', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/minimal_lda_model.pickle', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "    \n",
    "with open('../data/minimal_lda_tf.pickle', 'rb') as f:\n",
    "    tf = pickle.load(f)\n",
    "    \n",
    "with open('../data/minimal_lda_tf_vectorizer.pickle', 'rb') as f:\n",
    "    tf_vectorizer = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el37961401799325678569285054448\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el37961401799325678569285054448_data = {\"mdsDat\": {\"x\": [-0.17049805679754546, 0.33457975204282714, -0.21510936311724943, 0.051027667871967844], \"y\": [0.06842189969404983, -0.13716683259027473, -0.20309519487826092, 0.2718401277744859], \"topics\": [1, 2, 3, 4], \"cluster\": [1, 1, 1, 1], \"Freq\": [53.66114812290257, 17.800761664219735, 16.993208820578094, 11.544881392299612]}, \"tinfo\": {\"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\"], \"Freq\": [76787.0, 28422.0, 35518.0, 93096.0, 71532.0, 75532.0, 26333.0, 19823.0, 78705.0, 26520.0, 18618.0, 13422.0, 19257.0, 15713.0, 12159.0, 18062.0, 21713.0, 16822.0, 14036.0, 74742.0, 34335.0, 50512.0, 16313.0, 8955.0, 16616.0, 7860.0, 10334.0, 8276.0, 7548.0, 23687.0, 71531.5762159158, 23314.118375552764, 13441.369400600503, 11944.62845991082, 12110.402706087983, 10790.538197076816, 10599.15590678311, 9748.638034900934, 7897.85598282713, 6763.046737243301, 6924.6884123546215, 6604.765604914423, 6943.883996966624, 6451.16273429092, 6125.427319333762, 5948.785270909246, 5134.528133499474, 5543.695025510577, 4784.303115192239, 5350.204822351781, 4394.444091151431, 4303.221069119547, 4162.872386574487, 4500.202816361437, 4065.098801406662, 4082.7909413660363, 3771.176282581617, 3821.829178459878, 3593.5094004207804, 3485.108538594093, 75383.45402430862, 92679.62074099842, 77320.90551448228, 15711.571088288634, 14321.65895752348, 21672.825275828032, 9255.074819495218, 9162.97815527113, 11147.531618290514, 8448.90712556894, 7373.463756687846, 8747.819378691318, 7028.808238163777, 5749.304426748358, 20133.931588835057, 21010.27051955013, 48241.5649145209, 70402.4731258709, 20099.87152086409, 8201.860133183602, 28868.832447676676, 12885.844622438975, 9997.054929981281, 35287.45756719342, 31105.926521223457, 10532.210532220392, 26621.255245533033, 14317.830794075293, 14735.185584638588, 21099.20094350797, 24633.75380103511, 15693.002941667028, 14811.364652077416, 13411.858390988891, 8775.670510819537, 5555.087675694316, 5255.5051178747, 4582.409953698283, 3585.8455521707037, 3429.0094255170156, 3122.7541863005254, 2728.8778045380823, 2745.9309045603122, 2645.427671898577, 2492.6028401975764, 2504.731588367604, 2302.4511213520905, 2568.1477296589087, 2190.06223006072, 2225.29129462055, 2013.3979938737414, 2128.932862372996, 1918.18192028952, 2385.6691699872185, 2750.1036549124906, 1854.6967277122033, 1761.2636318383172, 1747.1052595244212, 7907.79530931315, 1639.3417892521286, 1631.2019457497206, 2439.5290102370445, 1612.7120993272258, 3939.191594149775, 6371.878115841749, 5650.71991949587, 5607.9523394564185, 4644.150782821825, 4232.683329979213, 4618.455008066555, 4920.568670562344, 6061.811739946548, 4343.9501320627505, 3016.9510975899016, 9343.602738941227, 2932.9516059801003, 4294.447561776598, 7685.321777390289, 10182.457624768718, 8910.600024404872, 13597.992732934174, 4204.623297298313, 18256.905061208156, 4908.230853242662, 3967.0421111770797, 8916.508590934196, 10115.857445427704, 5832.096353058298, 7509.19056830696, 12882.72055022662, 5221.406784650453, 5608.853669920936, 8985.189157418323, 8070.563431374479, 4827.656078009537, 4480.762807699128, 3543.114321342521, 2801.1942082085407, 2651.6865909744874, 2432.0847224616055, 1964.1081606465189, 1842.839595748706, 2113.292100906967, 1161.6450496586895, 1150.739985531647, 1085.2005249955114, 1076.8575145381508, 1061.1005918259934, 975.0523246336509, 1182.0741106237451, 948.9089909289954, 908.3484524354411, 826.7216245539685, 800.0434220691023, 15698.628788307422, 739.237876332444, 774.3956094171251, 743.1585413680511, 726.3379584475981, 708.5934643394736, 708.1197851134094, 707.8035638261068, 5942.756180204865, 19481.727602879007, 7095.515323829177, 1667.5830973398354, 1695.0999428870252, 1824.8672402486256, 1381.3799311563273, 1103.2378965684954, 73454.82666599566, 1253.4568906880272, 4919.014680516884, 8880.87232165161, 3159.1698375486926, 2778.928708836317, 2025.161016103451, 6161.457128391897, 2536.375981769137, 14443.874660677164, 3463.854008933462, 5259.480049054342, 6406.379009878254, 7224.552373220598, 14974.127875549546, 17233.263171943665, 3279.1820625841033, 4616.727811298913, 4179.488928212208, 3875.2205628878423, 4319.757298570225, 6198.117846119104, 7680.452974605883, 7580.4495698157125, 5549.214351964299, 8760.56339220225, 9686.440932491461, 5727.011996085178, 6050.949941149257, 4489.762209761371, 6529.633616442543, 5895.0918547492865, 5317.403123188758, 7860.139351696628, 7548.032392618547, 12157.684443634873, 3792.589752409129, 1941.34556005344, 1293.4818347384867, 2753.3334288049978, 3069.9924980793544, 821.1712444607848, 1349.0171596803714, 831.5432229093957, 685.4774516532514, 3848.9959172859567, 675.4879527621423, 584.4380803447494, 610.9843679871351, 3945.8281982611315, 454.7865134409699, 436.34004518383995, 1209.0962612218636, 420.07209373979356, 420.2728818426409, 389.79040594707965, 363.07875276224235, 338.3241818851464, 324.9777917811077, 423.09317455323117, 1032.0079094627717, 274.5776881333917, 272.9744159864762, 13230.656097615647, 1011.4077822103767, 575.5700525331679, 2271.7585175671134, 544.7947866030875, 468.7567478450455, 2202.928706220712, 2448.670029504111, 1444.9184941209587, 8623.247994525529, 1464.3914097820452, 1663.4396601386513, 2187.5181689157926, 26136.46049669996, 1213.6025541919175, 7546.761036516293, 1517.1493302979309, 1061.6018147598522, 4516.349076366647, 2783.143067374033, 2447.870929374073, 1890.4105258295858, 25303.791250381222, 3531.9379692303937, 13905.857007849585, 3754.111068216355, 4381.802304562477, 17418.249385170584, 4506.570774715551, 3107.3735939109824, 10511.86937259614, 5130.621772204669, 5762.00314271008, 8875.248414554944, 3771.316900725383, 6152.414620987016, 4765.756501872286, 3483.098033892967, 4964.224769818619, 3281.604912181331], \"Term\": [\"self\", \"react\", \"from\", \"this\", \"the\", \"if\", \"default\", \"def\", \"function\", \"import\", \"nimport\", \"nexport\", \"12\", \"nfrom\", \"createsvgicon\", \"path\", \"none\", \"user\", \"16\", \"return\", \"in\", \"var\", \"as\", \"fragment\", \"10\", \"xd0\", \"24\", \"classname\", \"xe0\", \"name\", \"the\", \"of\", \"it\", \"options\", \"be\", \"that\", \"or\", \"error\", \"an\", \"expect\", \"element\", \"render\", \"are\", \"should\", \"param\", \"tif\", \"will\", \"values\", \"foo\", \"no\", \"when\", \"find\", \"treturn\", \"obj\", \"elem\", \"let\", \"wrapper\", \"attr\", \"version\", \"each\", \"if\", \"this\", \"function\", \"else\", \"new\", \"value\", \"we\", \"event\", \"key\", \"use\", \"exports\", \"string\", \"license\", \"args\", \"length\", \"null\", \"var\", \"return\", \"and\", \"set\", \"is\", \"object\", \"code\", \"to\", \"for\", \"text\", \"true\", \"const\", \"type\", \"data\", \"in\", \"false\", \"name\", \"assert\", \"48\", \"26\", \"33\", \"35\", \"expect_equal\", \"49\", \"51\", \"ntest_that\", \"46\", \"57\", \"96\", \"66\", \"63\", \"52\", \"373\", \"71\", \"62\", \"69\", \"76\", \"54\", \"56\", \"88\", \"627\", \"84\", \"21\", \"73\", \"82\", \"53\", \"78\", \"67\", \"22\", \"28\", \"19\", \"34\", \"512\", \"29\", \"39\", \"18\", \"23\", \"44\", \"32\", \"58\", \"41\", \"17\", \"24\", \"13\", \"16\", \"64\", \"12\", \"31\", \"27\", \"14\", \"11\", \"25\", \"15\", \"10\", \"20\", \"45\", \"ndef\", \"assertequal\", \"django\", \"user_profile\", \"zerver\", \"status_code\", \"kwargs\", \"migrations\", \"__init__\", \"pytest\", \"hamlet\", \"example_email\", \"asserttrue\", \"classmethod\", \"example_user\", \"is_valid\", \"graphene\", \"expected_message\", \"api_link\", \"__future__\", \"model_name\", \"ujson\", \"nfrom\", \"assertfalse\", \"unicode_literals\", \"expected_topic\", \"charfield\", \"user_acl\", \"admin_client\", \"return_value\", \"realm\", \"def\", \"models\", \"isinstance\", \"userprofile\", \"elif\", \"subreddit\", \"valueerror\", \"self\", \"admin\", \"dict\", \"response\", \"pk\", \"raise\", \"product\", \"email\", \"cls\", \"user\", \"zulip\", \"nclass\", \"request\", \"str\", \"none\", \"import\", \"client\", \"thread\", \"category\", \"objects\", \"post\", \"get\", \"id\", \"not\", \"result\", \"name\", \"in\", \"message\", \"assert\", \"url\", \"true\", \"data\", \"for\", \"xd0\", \"xe0\", \"createsvgicon\", \"xd1\", \"xd9\", \"xd5\", \"xd8\", \"0h24v24h0v0z\", \"withstyles\", \"typography\", \"snackbar\", \"0h24v24h0z\", \"material\", \"nplot\", \"markdowndocs\", \"plot_height\", \"xe1\", \"add_layout\", \"nshow\", \"xce\", \"m19\", \"line_color\", \"formcontrol\", \"iconbutton\", \"noutput_file\", \"linearaxis\", \"listitem\", \"xd7\", \"2v5c0\", \"toolbar_location\", \"nexport\", \"xe6\", \"plot_width\", \"xb5\", \"xcf\", \"xec\", \"xa4\", \"x83\", \"x9e\", \"fragment\", \"xbd\", \"xb4\", \"xc3\", \"react\", \"xbf\", \"classname\", \"xb0\", \"xa5\", \"proptypes\", \"x80\", \"xb8\", \"gettext\", \"from\", \"m0\", \"nimport\", \"classes\", \"theme\", \"default\", \"createelement\", \"xe2\", \"path\", \"utils\", \"props\", \"import\", \"button\", \"as\", \"div\", \"fill\", \"none\", \"ui\"], \"Total\": [76787.0, 28422.0, 35518.0, 93096.0, 71532.0, 75532.0, 26333.0, 19823.0, 78705.0, 26520.0, 18618.0, 13422.0, 19257.0, 15713.0, 12159.0, 18062.0, 21713.0, 16822.0, 14036.0, 74742.0, 34335.0, 50512.0, 16313.0, 8955.0, 16616.0, 7860.0, 10334.0, 8276.0, 7548.0, 23687.0, 71532.33827324439, 23314.9213655403, 13442.104197884266, 11945.392786185233, 12111.178002713159, 10791.313410572558, 10600.105663359696, 9749.527312061326, 7898.68628126962, 6763.760860921248, 6925.4206044579605, 6605.51012600276, 6944.680049638876, 6451.9083698687145, 6126.153037192501, 5949.5006619247915, 5135.275451272646, 5544.516578836984, 4785.053215959941, 5351.077395704079, 4395.187218481435, 4303.9570716834605, 4163.586390747376, 4500.983197389691, 4065.8119518237395, 4083.521844699419, 3771.90765530384, 3822.5820559890158, 3594.2526191901266, 3485.8466619203346, 75532.8277666101, 93096.294402732, 78705.21868793233, 15739.469653395687, 14335.20102204415, 21814.028785438175, 9260.236456978297, 9170.77855365649, 11191.726103153453, 8462.624566897684, 7379.261253068549, 8781.229893316891, 7044.088020561369, 5751.038056204535, 20605.032306683504, 21534.63753531464, 50512.03949784867, 74742.26522392403, 20731.70300235176, 8256.713452217458, 30950.48335540427, 13266.478324341713, 10177.586889123753, 39556.085568982315, 36533.660113306, 10933.048124080498, 33151.423650289864, 16030.78207531458, 16631.042165459337, 27079.816984416346, 34335.688463508995, 20045.57877530655, 23687.58454991684, 19463.338392911483, 8776.37291302736, 5555.770349541208, 5256.244670329695, 4583.112968613452, 3586.5128094694574, 3429.6938187180976, 3123.494299274231, 2729.5448165993844, 2746.6058610475093, 2646.142674458571, 2493.2896693546086, 2505.4372944026063, 2303.121077899065, 2568.9084522917497, 2190.7227961418043, 2225.9644623025765, 2014.0660919676754, 2129.6635361175395, 1918.8553290031437, 2386.5251038837096, 2751.1196405967444, 1855.3823238337125, 1761.9196331829564, 1747.770248030332, 7910.951064786229, 1640.0159912172956, 1631.8749245154688, 2440.5458981799966, 1613.3910902230627, 3940.888237487681, 6384.8052039932, 5659.581231736911, 5624.261376227327, 4649.086081278456, 4238.608235662848, 4635.729299903474, 4942.641181799957, 6108.306775232582, 4362.720609991424, 3020.9020649780246, 9464.945734300496, 2936.782678429668, 4318.62377611249, 7774.587616483963, 10334.294692219337, 9071.082563766477, 14036.390500983734, 4245.369402201531, 19257.15550533714, 4975.988831835567, 4023.0988829342514, 9384.222242833275, 10840.563955888263, 6107.14449036935, 8270.48126782388, 16616.060274526048, 6367.147909587986, 8100.099275207182, 8985.926795134275, 8071.290086010818, 4828.381451393734, 4481.4905968821995, 3543.8599437804573, 2801.9174629863946, 2652.4190493939755, 2432.81172613344, 1964.8559869902774, 1843.7561582586552, 2114.382107229447, 1162.3691570091225, 1151.4635266361026, 1085.9286393058778, 1077.5828859089029, 1061.8303139091786, 975.7798749258367, 1182.9568136432954, 949.6334475928707, 909.129580609294, 827.4464953656187, 800.7691446299357, 15713.059959496475, 739.9610889159768, 775.1579180295544, 743.8954095246269, 727.0627151728513, 709.316743170656, 708.8431974021549, 708.5268301519706, 5964.348031270713, 19823.074200299514, 7164.020025894065, 1670.1319256435677, 1698.7594031168362, 1832.1518016460739, 1385.9262101286035, 1104.718657455218, 76787.86537664248, 1261.3441799822383, 5111.034355251054, 9405.74935080925, 3249.442170622555, 2850.676309975858, 2063.9408055688314, 6540.90693236394, 2638.9563224216954, 16822.69015935666, 3746.2981384428285, 5872.057464458774, 7447.665867006678, 9024.955540305582, 21713.103819632066, 26520.25322310134, 3701.168738058585, 5639.803211845257, 5095.989368272355, 4731.746075190386, 6053.18520823157, 11412.50853583716, 16641.784473086514, 17368.5881260019, 9888.403960149144, 23687.58454991684, 34335.688463508995, 12084.066186019674, 19463.338392911483, 7875.586946788322, 33151.423650289864, 27079.816984416346, 36533.660113306, 7860.835654065688, 7548.803455158319, 12159.814428801856, 3793.297947808511, 1942.0900974910094, 1294.2709279097796, 2755.015655744271, 3072.2139682902616, 821.8700331512792, 1350.1701128807026, 832.2714191945868, 686.1680840414537, 3852.889526239056, 676.1814509720997, 585.122608296435, 611.7239717120167, 3951.298076323524, 455.4760420764633, 437.029186765784, 1211.017728855576, 420.7672551237706, 420.9704887596009, 390.4899247046266, 363.76473878915255, 339.01367452154966, 325.66911866643306, 424.13168475449254, 1034.5692628196682, 275.2658679166891, 273.6660025138536, 13422.504328828963, 1014.1083571440071, 577.4487266344809, 2312.6130126918856, 546.9096595581752, 470.0046362241031, 2243.593503416439, 2496.587780242106, 1465.4681970328538, 8955.595562897726, 1487.0255176415312, 1699.4073477236082, 2248.312348546378, 28422.863801483887, 1241.4773696890368, 8276.00769187809, 1563.0314063494131, 1081.5153692297438, 4899.945260960806, 2961.8468530083383, 2614.6590091774074, 2012.1203079915283, 35518.68845939204, 4032.2494468143686, 18618.241233040353, 4406.066268897353, 5290.645351664439, 26333.112556637796, 5809.050619726426, 3715.4164268489544, 18062.283987050265, 7309.065558419117, 10334.712204607564, 26520.25322310134, 5993.534880649775, 16313.42757976747, 11566.05140273882, 6022.766771809179, 21713.103819632066, 7342.754501913136], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.6225, 0.6224, 0.6224, 0.6224, 0.6224, 0.6224, 0.6224, 0.6224, 0.6224, 0.6224, 0.6224, 0.6224, 0.6224, 0.6224, 0.6224, 0.6224, 0.6223, 0.6223, 0.6223, 0.6223, 0.6223, 0.6223, 0.6223, 0.6223, 0.6223, 0.6223, 0.6223, 0.6223, 0.6223, 0.6223, 0.6205, 0.618, 0.6047, 0.6207, 0.6215, 0.616, 0.6219, 0.6216, 0.6185, 0.6209, 0.6217, 0.6187, 0.6203, 0.6222, 0.5994, 0.5978, 0.5765, 0.5627, 0.5915, 0.6158, 0.5529, 0.5934, 0.6046, 0.5083, 0.4616, 0.5851, 0.4031, 0.5095, 0.5014, 0.3729, 0.2904, 0.3777, 0.1529, 0.2501, 1.7258, 1.7258, 1.7258, 1.7258, 1.7257, 1.7257, 1.7257, 1.7257, 1.7257, 1.7257, 1.7257, 1.7256, 1.7256, 1.7256, 1.7256, 1.7256, 1.7256, 1.7256, 1.7256, 1.7256, 1.7256, 1.7256, 1.7256, 1.7255, 1.7255, 1.7255, 1.7255, 1.7255, 1.7255, 1.7255, 1.7239, 1.7244, 1.723, 1.7249, 1.7245, 1.7222, 1.7215, 1.7183, 1.7216, 1.7246, 1.713, 1.7246, 1.7203, 1.7144, 1.7111, 1.7081, 1.6942, 1.7163, 1.6726, 1.7122, 1.7119, 1.6748, 1.6567, 1.6798, 1.6294, 1.4714, 1.5275, 1.3584, 1.7723, 1.7723, 1.7722, 1.7722, 1.7721, 1.7721, 1.7721, 1.7721, 1.772, 1.7719, 1.7718, 1.7717, 1.7717, 1.7717, 1.7717, 1.7717, 1.7716, 1.7716, 1.7716, 1.7715, 1.7715, 1.7714, 1.7714, 1.7714, 1.7714, 1.7714, 1.7714, 1.7713, 1.7713, 1.7713, 1.7687, 1.755, 1.7627, 1.7708, 1.7702, 1.7684, 1.7691, 1.771, 1.728, 1.7661, 1.7341, 1.7149, 1.7442, 1.7469, 1.7534, 1.7126, 1.7327, 1.6199, 1.694, 1.6622, 1.6217, 1.5498, 1.4008, 1.3413, 1.6513, 1.5722, 1.5741, 1.5727, 1.435, 1.1619, 0.9991, 0.9433, 1.1947, 0.7777, 0.5069, 1.0257, 0.604, 1.2104, 0.1476, 0.2477, -0.1549, 2.1588, 2.1588, 2.1588, 2.1587, 2.1585, 2.1583, 2.1583, 2.1582, 2.1581, 2.1581, 2.1581, 2.1579, 2.1579, 2.1579, 2.1578, 2.1577, 2.1575, 2.1574, 2.1573, 2.1573, 2.1573, 2.1573, 2.1571, 2.157, 2.1569, 2.1568, 2.1565, 2.1564, 2.1564, 2.1564, 2.1445, 2.1563, 2.1557, 2.1411, 2.1551, 2.1563, 2.1406, 2.1395, 2.1448, 2.1211, 2.1436, 2.1375, 2.1315, 2.0751, 2.1362, 2.0667, 2.1291, 2.1403, 2.0774, 2.0967, 2.093, 2.0965, 1.8198, 2.0265, 1.8671, 1.9988, 1.9704, 1.7456, 1.905, 1.9802, 1.6176, 1.805, 1.5747, 1.0643, 1.6957, 1.1838, 1.2723, 1.6113, 0.6833, 1.3535], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -3.8881, -5.0092, -5.5599, -5.678, -5.6642, -5.7796, -5.7975, -5.8811, -6.0917, -6.2468, -6.2232, -6.2705, -6.2204, -6.294, -6.3458, -6.3751, -6.5223, -6.4456, -6.5929, -6.4811, -6.6779, -6.6989, -6.732, -6.6541, -6.7558, -6.7515, -6.8309, -6.8175, -6.8791, -6.9097, -3.8357, -3.6291, -3.8103, -5.4039, -5.4965, -5.0822, -5.9331, -5.9431, -5.747, -6.0242, -6.1604, -5.9894, -6.2082, -6.4092, -5.1558, -5.1132, -4.282, -3.904, -5.1575, -6.0539, -4.7955, -5.6021, -5.856, -4.5947, -4.7209, -5.8038, -4.8765, -5.4967, -5.468, -5.109, -4.9541, -5.405, -5.4629, -5.5621, -4.8828, -5.3401, -5.3955, -5.5326, -5.7778, -5.8225, -5.9161, -6.0509, -6.0447, -6.082, -6.1415, -6.1366, -6.2208, -6.1116, -6.2709, -6.2549, -6.355, -6.2992, -6.4034, -6.1853, -6.0432, -6.4371, -6.4888, -6.4968, -4.987, -6.5605, -6.5655, -6.163, -6.5769, -5.6838, -5.2029, -5.323, -5.3306, -5.5192, -5.612, -5.5247, -5.4614, -5.2528, -5.586, -5.9506, -4.8201, -5.9788, -5.5975, -5.0155, -4.7341, -4.8676, -4.4449, -5.6186, -4.1503, -5.4639, -5.6768, -4.8669, -4.7407, -5.2914, -5.0387, -4.4989, -5.402, -5.3305, -4.8128, -4.9201, -5.434, -5.5086, -5.7434, -5.9783, -6.0332, -6.1196, -6.3333, -6.3971, -6.2601, -6.8585, -6.868, -6.9266, -6.9343, -6.9491, -7.0336, -6.8411, -7.0608, -7.1045, -7.1987, -7.2315, -4.2548, -7.3105, -7.264, -7.3052, -7.3281, -7.3528, -7.3535, -7.354, -5.2262, -4.0389, -5.0489, -6.497, -6.4806, -6.4069, -6.6853, -6.9101, -2.7117, -6.7825, -5.4153, -4.8245, -5.8581, -5.9863, -6.3027, -5.1901, -6.0776, -4.3381, -5.766, -5.3483, -5.1511, -5.0309, -4.302, -4.1615, -5.8208, -5.4787, -5.5782, -5.6538, -5.5452, -5.1841, -4.9697, -4.9828, -5.2947, -4.8381, -4.7376, -5.2632, -5.2082, -5.5066, -5.132, -5.2343, -5.3374, -4.56, -4.6005, -4.1238, -5.2888, -5.9584, -6.3645, -5.609, -5.5001, -6.8188, -6.3224, -6.8063, -6.9994, -5.274, -7.0141, -7.1589, -7.1145, -5.2491, -7.4097, -7.4511, -6.4319, -7.4891, -7.4887, -7.5639, -7.6349, -7.7056, -7.7458, -7.482, -6.5903, -7.9143, -7.9202, -4.0393, -6.6105, -7.1742, -5.8012, -7.2291, -7.3795, -5.832, -5.7263, -6.2537, -4.4673, -6.2404, -6.1129, -5.839, -3.3585, -6.4282, -4.6007, -6.205, -6.562, -5.1141, -5.5982, -5.7266, -5.985, -3.3908, -5.36, -3.9895, -5.2989, -5.1443, -3.7643, -5.1163, -5.488, -4.2693, -4.9866, -4.8705, -4.4385, -5.2944, -4.805, -5.0603, -5.3739, -5.0195, -5.4335]}, \"token.table\": {\"Topic\": [2, 4, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 4, 1, 2, 3, 4, 1, 2, 3, 4, 2, 3, 4, 1, 2, 3, 4, 2, 3, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 2, 1, 2, 4, 2, 3, 4, 1, 2, 4, 1, 2, 3, 4, 1, 2, 3, 2, 2, 4, 2, 2, 1, 2, 3, 4, 2, 4, 2, 3, 2, 3, 4, 2, 2, 2, 2, 2, 3, 2, 2, 3, 2, 2, 4, 2, 2, 4, 2, 2, 2, 1, 2, 3, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 4, 1, 3, 4, 3, 1, 1, 2, 3, 3, 1, 1, 3, 1, 3, 4, 1, 3, 3, 3, 3, 1, 1, 1, 4, 1, 3, 4, 3, 1, 2, 4, 3, 1, 4, 1, 3, 1, 2, 3, 1, 2, 3, 1, 4, 1, 2, 4, 2, 4, 1, 2, 3, 1, 3, 1, 2, 3, 4, 1, 3, 1, 4, 3, 1, 1, 1, 1, 3, 1, 2, 4, 1, 3, 4, 1, 1, 4, 3, 3, 1, 2, 3, 3, 1, 4, 1, 3, 4, 1, 2, 3, 4, 1, 1, 1, 2, 3, 4, 1, 4, 1, 3, 4, 1, 2, 4, 1, 2, 3, 1, 3, 4, 3, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 1, 3, 4, 1, 2, 3, 1, 3, 3, 1, 3, 1, 1, 2, 4, 3, 1, 2, 1, 1, 2, 4, 4, 1, 4, 2, 4, 4, 4, 1, 4, 1, 3, 4, 3, 3, 1, 3, 4, 1, 3, 4, 1, 3, 4, 3, 1, 2, 1, 4, 3, 4, 1, 3, 4, 1, 1, 2, 3, 4, 1, 2, 3, 4, 4, 4, 2, 1, 2, 4, 1, 1, 2, 4, 1, 3, 1, 1, 1, 1, 1, 2, 3, 4, 1, 3, 4, 1, 4, 1, 3, 4, 1, 2, 3, 1, 4, 1, 4, 3, 1, 3, 1, 2, 4, 1, 3, 1, 1, 3, 1, 3, 1, 3, 1, 2, 3, 4, 3, 1, 3, 1, 3, 1, 4, 3, 1, 3, 1, 4, 1, 3, 1, 2, 4, 1, 1, 1, 4, 1, 4, 1, 3, 4, 1, 1, 3, 4, 1, 1, 3, 1, 3, 2, 4, 1, 4, 3, 3, 1, 3, 4, 1, 2, 1, 2, 3, 4, 3, 3, 1, 3, 1, 2, 3, 4, 1, 4, 1, 3, 1, 1, 2, 4, 1, 1, 2, 1, 1, 4, 1, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 3, 4, 1, 4, 1, 4, 4, 4, 4, 1, 4, 1, 4, 4, 4, 1, 2, 4, 1, 4, 1, 4, 1, 4, 3, 1, 2, 3], \"Freq\": [0.0006509963240330664, 0.9992793573907569, 0.9982976706894122, 0.10947240019276379, 0.7753342120304431, 0.053442271232091394, 0.06174748905870019, 0.0229692847174017, 0.9331617839407053, 0.009224612336305903, 0.0346845423845102, 0.015994054776918506, 0.9480631755266271, 0.0063353074116365505, 0.029651315836430086, 0.01355957231514032, 0.9823524300830521, 0.0034174531851166663, 0.0007716829772844086, 0.02674702212979755, 0.9502119375753177, 0.022484548483614673, 0.0006393710469274315, 0.050299370318198845, 0.9079278166330652, 0.035548112676803995, 0.00616650934189457, 0.02863984155839965, 0.9687675758983045, 0.0025647619306029537, 0.005016343235660601, 0.9884768657961979, 0.000385872556589277, 0.006045336719898673, 0.0027830953201188396, 0.9924190488564945, 0.002455672341281329, 0.002455672341281329, 0.9971087090126962, 0.0016002101250203755, 0.0012446078750158475, 0.07397346609315349, 0.8199903746759116, 0.04209105926319562, 0.06376481365991575, 0.9996269646010876, 0.0003792211550079999, 0.9979944252668521, 0.0014095966458571357, 0.00046986554861904524, 0.0006876443091793351, 0.9957089596916772, 0.0032090067761702304, 0.00045842953945289007, 0.0009676519102487926, 0.9852631750153207, 0.01045064063068696, 0.003193251303821016, 0.023415198416461832, 0.9549471130405972, 0.0027836249865723856, 0.018830404320930843, 0.9998613424434882, 0.01367105348399632, 0.9860558031093346, 0.0002485646087999331, 0.9984837691367003, 0.0005300745544877191, 0.0010601491089754383, 0.0036671684000948836, 0.9961755100963632, 0.9990341413604916, 0.004823161950535722, 0.986336618884555, 0.006430882600714296, 0.002210615893995539, 0.010248341905276518, 0.9872217192051936, 0.0026413252333186902, 0.9999534514953089, 0.9989060040641241, 0.0008603841550939915, 0.9997571588086365, 0.9996700649926694, 0.0024278517413295155, 0.9956215349235455, 0.00020232097844412629, 0.0018208888059971365, 0.9942982354127046, 0.005557325954798535, 0.998708311327513, 0.0009930808531596086, 0.6924606488673604, 0.0002469105540621716, 0.3072801845303726, 0.9997794146382262, 0.9999575094368647, 0.9997977024321206, 0.9998417479825894, 0.9986768685967103, 0.0011796324930270616, 0.9996463664203606, 0.9997763212810693, 0.00040974439396765133, 0.9997799713554846, 0.9995930236619948, 0.00036348837224072536, 0.999568173526847, 0.9987119651523924, 0.0010215260468657268, 0.9994706767707737, 0.999478050436787, 0.9995132353614307, 0.0018844061004094066, 0.9904909565276944, 0.0077731751641888025, 0.9998254618450906, 0.9995208599244914, 0.0002537499009709295, 0.9996884314792988, 0.9995667216081343, 0.9993804992007782, 0.9995542503959441, 0.9997575973826602, 0.9994638532020286, 0.9995592967489864, 0.9997939379777412, 0.9998838204167896, 0.998757514183471, 0.9995643512827682, 0.9989548471654117, 0.004756830130285684, 0.9933846922079937, 0.0015856100434285614, 0.998810459908136, 0.9999131145047186, 0.9695296135450089, 9.64706083129362e-05, 0.030388241618574903, 0.9993329556846631, 0.999902076174278, 0.9996456194195522, 0.00017388165236033263, 0.6208382604132272, 0.002022873478834567, 0.377112655811826, 0.6890904185730352, 0.31089219525689205, 0.9999640595236043, 0.9987011628984643, 0.9995974456633839, 0.9998477322447261, 0.999902734258146, 0.37073280530555736, 0.6291779517584414, 0.13343826897161168, 0.8200566559299488, 0.04631092864308876, 0.9985383445600031, 0.14366556501167022, 0.0043122365485335455, 0.8520071580628911, 0.9991448431579525, 0.08808595003064414, 0.9119131205504407, 0.1137478536633355, 0.8859363709312994, 0.03220970323676972, 0.006441940647353944, 0.9609859695111531, 0.9822564139131313, 0.0015720818868270583, 0.016113839339977346, 0.8931566739995765, 0.10679454015136716, 0.2239608647206572, 0.00017214516888597786, 0.7758582761691023, 0.00016447619424707506, 0.9998507848279693, 0.7791411593417291, 0.003138869071711786, 0.21768980209107036, 0.017202175432246915, 0.9827940814399837, 0.27877448912318387, 3.7975001923877386e-05, 0.059734678026259126, 0.6614485835100963, 0.03737012642142924, 0.9624274966859186, 0.5879275271411791, 0.41206802858159697, 0.9999209980823649, 0.999757114410802, 0.999800297742896, 0.9999392665829293, 0.003820644115684594, 0.9960965015891978, 0.9982547281451913, 0.0013342253876685985, 0.0004447417958895328, 0.04296040333636794, 0.94191830944969, 0.015135515766193689, 0.9999459140895299, 0.9991518109819162, 0.0007632939732482171, 0.9996824098377899, 0.9994590802094901, 0.9998875091924606, 0.9998570172485922, 0.9991911677313489, 0.9987963233632547, 0.9991515067899316, 0.0006775746011053382, 0.7828658965602759, 0.2165065947283246, 0.0006485220579419861, 0.040346905202674026, 0.38105410469192136, 0.00016603664692458445, 0.5783056412383277, 0.9997776298258741, 0.9997798946192641, 0.8514339900116062, 0.0030109219732937917, 0.14553701938184627, 0.9987453589103555, 0.03707179468615665, 0.9628617035503879, 0.2254587752910815, 0.062136303330097016, 0.7124136925531377, 0.9824126187436086, 0.011155549970342965, 0.006429052716393553, 0.4559908966252758, 0.0008762315461669404, 0.5430883123142697, 0.060135569190085156, 0.0004969881751246707, 0.9393076509856276, 0.999200767564615, 0.0004729514105235865, 0.9993463304363382, 0.9978977105046022, 0.5044531140020826, 0.0036654722994790994, 0.46148897147540135, 0.03040539317272827, 0.9980163887538666, 0.0010591421288660484, 0.0009135100861469667, 0.015497589579649447, 0.6498052584576617, 0.33464989664084877, 0.7174459316923358, 0.0004368632368021855, 0.2820971541110646, 0.9327479531901778, 0.06723642975471128, 0.9992180352187142, 0.0011975101902380084, 0.998723498658499, 0.9999178552800952, 0.9960929973848152, 0.002323144773233333, 0.0016083309968538458, 0.9998420123720378, 0.9771399384542232, 0.022858493643187597, 0.9998722071977902, 0.9978580590535882, 0.0021294452818044988, 0.9976946394450108, 0.9979454033923357, 0.002357758299946035, 0.9973317608771728, 0.12400026501213092, 0.8759378720456928, 0.9981765331916218, 0.9980814135695364, 0.0007786363921335704, 0.9989904911073708, 0.5255681243576449, 0.47392987690068217, 0.0004965216101631034, 0.9996663423952127, 0.999460393671229, 0.007258494506163868, 0.9905053272257462, 0.0023729693577843416, 0.6252642589534102, 0.369856199628035, 0.004854863937589776, 0.06318058061344176, 0.8955975025501084, 0.04104183268959424, 0.9998968614862546, 0.999079118456459, 0.0009068585770097729, 0.014229833369453168, 0.9857325932525387, 0.9991052055084931, 0.0008909785895355694, 0.1349751552010387, 0.11810997464667096, 0.7469019133408851, 0.9997986581721011, 0.06258893299129578, 0.01915893754553278, 0.6896296413625188, 0.22861770667313636, 0.5634885189860785, 5.7575203738232194e-05, 0.43642004433580006, 0.997009930283844, 0.9982527604529802, 0.9976450388281835, 0.9998004002000366, 0.9756375033267086, 0.024100707483415598, 0.0002321840798016917, 0.9997815594178932, 0.9713203221654084, 0.0052010788630617085, 0.02344254386104625, 0.18090573466911114, 0.8189365909378571, 0.9999604817221618, 0.999967118185876, 0.9998956931756333, 0.9998117844615535, 0.2950346702455028, 0.0099101531195243, 0.11310861912395612, 0.5819861988404438, 0.027697061610657027, 0.9721668625340616, 0.9988165058989097, 0.0017317554855965417, 0.9974911597036079, 0.05930761865865349, 0.7136738512684766, 0.22698793325066824, 0.013081770527114841, 0.005329610214750491, 0.981132789533613, 0.44239258041086504, 0.5575385057583999, 0.07816413849588585, 0.9216429489488787, 0.9995898816363171, 0.024906370376579615, 0.9748563841762641, 0.08025229322180105, 0.00017591471552345694, 0.9195414009842141, 0.003520921295990489, 0.9964207267653084, 0.9999227726560054, 0.13977533613741355, 0.8601352577293672, 0.05571060640212746, 0.9442097241551412, 0.43879679850119674, 0.5611623495927958, 0.9419302424013934, 0.004375034647669891, 0.012977931523669096, 0.040713242913943355, 0.9992564429044168, 0.04340529566295041, 0.956596457522359, 0.9933734587576412, 0.006540132500964718, 0.9998592091181957, 0.9996738813945463, 0.9996725588820818, 0.19944696591148553, 0.8005579603947128, 0.9962158041959269, 0.0037580157222754443, 0.002886156543376743, 0.9964455466008205, 0.9633178122396467, 0.0039330294271083185, 0.03265329082506209, 0.9999709571429691, 0.9999952710445017, 0.17162367530727474, 0.8282543449300417, 0.9955283461559584, 0.0044684914976357215, 0.03244794066850521, 0.818645585062779, 0.14894136700297472, 0.999915848076462, 0.8920751255445283, 0.1078974306635318, 0.9975663673684865, 0.9998591621039307, 0.803012271232196, 0.19697494951903533, 0.8859937852002331, 0.11394355093006052, 0.0007406474121001058, 0.9991333589230426, 0.5530622055989911, 0.44697122845995785, 0.9990394926738952, 0.998506216601002, 0.4259999950058547, 0.5701162377276565, 0.0038092398957304445, 0.9983900305643975, 0.0015361664572537776, 0.10997052091404318, 0.005528247808111359, 0.8586022724769944, 0.025917376820823148, 0.9995534531311919, 0.9998905281911021, 0.0017659946396739196, 0.9977869714157646, 0.10493817491026787, 0.00013681639492864128, 0.19291111684938422, 0.7020049223788585, 0.9935349500623967, 0.006463730353841089, 0.0009052078493030585, 0.9984442577812735, 0.999906830680432, 0.9550594369101775, 0.044919983880212115, 1.97972604143729e-05, 0.9999297157943831, 0.9994345223253613, 0.0005399430158429828, 0.9997298821591848, 0.999946360954683, 0.9989413981332994, 0.9997593643888488, 0.06009763800555926, 0.9396164414015248, 0.018825694963323977, 0.9809388715995834, 0.013647515545198574, 0.986032998140597, 0.01782854155135049, 0.9819069259406282, 0.017567942666900625, 0.9819555322236034, 0.02879020844827498, 0.9705499159118477, 0.020595415246899593, 0.9785764444455436, 0.01729645201357746, 0.9824384743711997, 0.06348820225403883, 0.9362597537222112, 0.014794635155214206, 0.9845157212378908, 0.021748282054277732, 0.9778672005145618, 0.019570234548792885, 0.007561226984760888, 0.973174390744519, 0.00082575174266442, 0.9983338568812838, 0.0036569110913413265, 0.9965082723905115, 0.9998936939910128, 0.999921454150818, 0.9990180356505171, 0.0019331716801145795, 0.997516586939123, 0.0003629743438716862, 0.999268368678752, 0.9994386988057775, 0.9998935652301598, 0.0007592441628173349, 0.0005061627752115566, 0.9986591554924011, 0.16364249121750396, 0.836245427981554, 0.001972175838913822, 0.996934886570937, 0.002127638586788726, 0.9978624972039125, 0.9997573426167796, 0.07260500631512964, 0.0029362318730383314, 0.9246461098367982], \"Term\": [\"0h24v24h0v0z\", \"0h24v24h0v0z\", \"0h24v24h0z\", \"10\", \"10\", \"10\", \"10\", \"11\", \"11\", \"11\", \"11\", \"12\", \"12\", \"12\", \"12\", \"13\", \"13\", \"13\", \"13\", \"14\", \"14\", \"14\", \"14\", \"15\", \"15\", \"15\", \"15\", \"16\", \"16\", \"16\", \"17\", \"17\", \"17\", \"17\", \"18\", \"18\", \"18\", \"18\", \"19\", \"19\", \"19\", \"20\", \"20\", \"20\", \"20\", \"21\", \"21\", \"22\", \"22\", \"22\", \"23\", \"23\", \"23\", \"23\", \"24\", \"24\", \"24\", \"24\", \"25\", \"25\", \"25\", \"25\", \"26\", \"27\", \"27\", \"27\", \"28\", \"28\", \"28\", \"29\", \"29\", \"2v5c0\", \"31\", \"31\", \"31\", \"31\", \"32\", \"32\", \"32\", \"33\", \"34\", \"34\", \"35\", \"373\", \"39\", \"39\", \"39\", \"39\", \"41\", \"41\", \"44\", \"44\", \"45\", \"45\", \"45\", \"46\", \"48\", \"49\", \"51\", \"512\", \"512\", \"52\", \"53\", \"53\", \"54\", \"56\", \"56\", \"57\", \"58\", \"58\", \"62\", \"627\", \"63\", \"64\", \"64\", \"64\", \"66\", \"67\", \"67\", \"69\", \"71\", \"73\", \"76\", \"78\", \"82\", \"84\", \"88\", \"96\", \"__future__\", \"__init__\", \"add_layout\", \"admin\", \"admin\", \"admin\", \"admin_client\", \"an\", \"and\", \"and\", \"and\", \"api_link\", \"are\", \"args\", \"args\", \"as\", \"as\", \"as\", \"assert\", \"assert\", \"assertequal\", \"assertfalse\", \"asserttrue\", \"attr\", \"be\", \"button\", \"button\", \"category\", \"category\", \"category\", \"charfield\", \"classes\", \"classes\", \"classes\", \"classmethod\", \"classname\", \"classname\", \"client\", \"client\", \"cls\", \"cls\", \"cls\", \"code\", \"code\", \"code\", \"const\", \"const\", \"createelement\", \"createelement\", \"createelement\", \"createsvgicon\", \"createsvgicon\", \"data\", \"data\", \"data\", \"def\", \"def\", \"default\", \"default\", \"default\", \"default\", \"dict\", \"dict\", \"div\", \"div\", \"django\", \"each\", \"elem\", \"element\", \"elif\", \"elif\", \"else\", \"else\", \"else\", \"email\", \"email\", \"email\", \"error\", \"event\", \"event\", \"example_email\", \"example_user\", \"expect\", \"expect_equal\", \"expected_message\", \"expected_topic\", \"exports\", \"exports\", \"false\", \"false\", \"false\", \"fill\", \"fill\", \"fill\", \"fill\", \"find\", \"foo\", \"for\", \"for\", \"for\", \"formcontrol\", \"fragment\", \"fragment\", \"from\", \"from\", \"from\", \"function\", \"function\", \"function\", \"get\", \"get\", \"get\", \"gettext\", \"gettext\", \"gettext\", \"graphene\", \"hamlet\", \"hamlet\", \"iconbutton\", \"id\", \"id\", \"id\", \"id\", \"if\", \"if\", \"if\", \"import\", \"import\", \"import\", \"in\", \"in\", \"in\", \"is\", \"is\", \"is_valid\", \"isinstance\", \"isinstance\", \"it\", \"key\", \"key\", \"key\", \"kwargs\", \"length\", \"length\", \"let\", \"license\", \"license\", \"line_color\", \"linearaxis\", \"listitem\", \"listitem\", \"m0\", \"m0\", \"m19\", \"markdowndocs\", \"material\", \"material\", \"message\", \"message\", \"message\", \"migrations\", \"model_name\", \"models\", \"models\", \"models\", \"name\", \"name\", \"name\", \"nclass\", \"nclass\", \"nclass\", \"ndef\", \"new\", \"new\", \"nexport\", \"nexport\", \"nfrom\", \"nfrom\", \"nimport\", \"nimport\", \"nimport\", \"no\", \"none\", \"none\", \"none\", \"none\", \"not\", \"not\", \"not\", \"noutput_file\", \"nplot\", \"nshow\", \"ntest_that\", \"null\", \"null\", \"null\", \"obj\", \"object\", \"object\", \"object\", \"objects\", \"objects\", \"of\", \"options\", \"or\", \"param\", \"path\", \"path\", \"path\", \"path\", \"pk\", \"pk\", \"plot_height\", \"plot_width\", \"plot_width\", \"post\", \"post\", \"post\", \"product\", \"product\", \"product\", \"props\", \"props\", \"proptypes\", \"proptypes\", \"pytest\", \"raise\", \"raise\", \"react\", \"react\", \"react\", \"realm\", \"realm\", \"render\", \"request\", \"request\", \"response\", \"response\", \"result\", \"result\", \"return\", \"return\", \"return\", \"return\", \"return_value\", \"self\", \"self\", \"set\", \"set\", \"should\", \"snackbar\", \"status_code\", \"str\", \"str\", \"string\", \"string\", \"subreddit\", \"subreddit\", \"text\", \"text\", \"text\", \"that\", \"the\", \"theme\", \"theme\", \"this\", \"this\", \"thread\", \"thread\", \"thread\", \"tif\", \"to\", \"to\", \"toolbar_location\", \"treturn\", \"true\", \"true\", \"type\", \"type\", \"typography\", \"typography\", \"ui\", \"ui\", \"ujson\", \"unicode_literals\", \"url\", \"url\", \"url\", \"use\", \"use\", \"user\", \"user\", \"user\", \"user\", \"user_acl\", \"user_profile\", \"userprofile\", \"userprofile\", \"utils\", \"utils\", \"utils\", \"utils\", \"value\", \"value\", \"valueerror\", \"valueerror\", \"values\", \"var\", \"var\", \"var\", \"version\", \"we\", \"we\", \"when\", \"will\", \"withstyles\", \"wrapper\", \"x80\", \"x80\", \"x83\", \"x83\", \"x9e\", \"x9e\", \"xa4\", \"xa4\", \"xa5\", \"xa5\", \"xb0\", \"xb0\", \"xb4\", \"xb4\", \"xb5\", \"xb5\", \"xb8\", \"xb8\", \"xbd\", \"xbd\", \"xbf\", \"xbf\", \"xc3\", \"xc3\", \"xc3\", \"xce\", \"xce\", \"xcf\", \"xcf\", \"xd0\", \"xd1\", \"xd5\", \"xd7\", \"xd7\", \"xd8\", \"xd8\", \"xd9\", \"xe0\", \"xe1\", \"xe1\", \"xe1\", \"xe2\", \"xe2\", \"xe6\", \"xe6\", \"xec\", \"xec\", \"zerver\", \"zulip\", \"zulip\", \"zulip\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 4, 2, 3]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el37961401799325678569285054448\", ldavis_el37961401799325678569285054448_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el37961401799325678569285054448\", ldavis_el37961401799325678569285054448_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el37961401799325678569285054448\", ldavis_el37961401799325678569285054448_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "0     -0.170498  0.068422       1        1  53.661148\n",
       "3      0.334580 -0.137167       2        1  17.800762\n",
       "1     -0.215109 -0.203095       3        1  16.993209\n",
       "2      0.051028  0.271840       4        1  11.544881, topic_info=       Category          Freq           Term         Total  loglift  logprob\n",
       "term                                                                        \n",
       "224987  Default  76787.000000           self  76787.000000  30.0000  30.0000\n",
       "209790  Default  28422.000000          react  28422.000000  29.0000  29.0000\n",
       "118970  Default  35518.000000           from  35518.000000  28.0000  28.0000\n",
       "257199  Default  93096.000000           this  93096.000000  27.0000  27.0000\n",
       "256596  Default  71532.000000            the  71532.000000  26.0000  26.0000\n",
       "138187  Default  75532.000000             if  75532.000000  25.0000  25.0000\n",
       "93741   Default  26333.000000        default  26333.000000  24.0000  24.0000\n",
       "93727   Default  19823.000000            def  19823.000000  23.0000  23.0000\n",
       "119762  Default  78705.000000       function  78705.000000  22.0000  22.0000\n",
       "139197  Default  26520.000000         import  26520.000000  21.0000  21.0000\n",
       "180274  Default  18618.000000        nimport  18618.000000  20.0000  20.0000\n",
       "178605  Default  13422.000000        nexport  13422.000000  19.0000  19.0000\n",
       "6203    Default  19257.000000             12  19257.000000  18.0000  18.0000\n",
       "179191  Default  15713.000000          nfrom  15713.000000  17.0000  17.0000\n",
       "88624   Default  12159.000000  createsvgicon  12159.000000  16.0000  16.0000\n",
       "195902  Default  18062.000000           path  18062.000000  15.0000  15.0000\n",
       "182715  Default  21713.000000           none  21713.000000  14.0000  14.0000\n",
       "270897  Default  16822.000000           user  16822.000000  13.0000  13.0000\n",
       "10108   Default  14036.000000             16  14036.000000  12.0000  12.0000\n",
       "216978  Default  74742.000000         return  74742.000000  11.0000  11.0000\n",
       "139409  Default  34335.000000             in  34335.000000  10.0000  10.0000\n",
       "273107  Default  50512.000000            var  50512.000000   9.0000   9.0000\n",
       "58561   Default  16313.000000             as  16313.000000   8.0000   8.0000\n",
       "118218  Default   8955.000000       fragment   8955.000000   7.0000   7.0000\n",
       "4646    Default  16616.000000             10  16616.000000   6.0000   6.0000\n",
       "281843  Default   7860.000000            xd0   7860.000000   5.0000   5.0000\n",
       "16221   Default  10334.000000             24  10334.000000   4.0000   4.0000\n",
       "80378   Default   8276.000000      classname   8276.000000   3.0000   3.0000\n",
       "281885  Default   7548.000000            xe0   7548.000000   2.0000   2.0000\n",
       "173909  Default  23687.000000           name  23687.000000   1.0000   1.0000\n",
       "...         ...           ...            ...           ...      ...      ...\n",
       "281761   Topic4   1464.391410            xbd   1487.025518   2.1436  -6.2404\n",
       "281631   Topic4   1663.439660            xb4   1699.407348   2.1375  -6.1129\n",
       "281809   Topic4   2187.518169            xc3   2248.312349   2.1315  -5.8390\n",
       "209790   Topic4  26136.460497          react  28422.863801   2.0751  -3.3585\n",
       "281786   Topic4   1213.602554            xbf   1241.477370   2.1362  -6.4282\n",
       "80378    Topic4   7546.761037      classname   8276.007692   2.0667  -4.6007\n",
       "281561   Topic4   1517.149330            xb0   1563.031406   2.1291  -6.2050\n",
       "281345   Topic4   1061.601815            xa5   1081.515369   2.1403  -6.5620\n",
       "205348   Topic4   4516.349076      proptypes   4899.945261   2.0774  -5.1141\n",
       "280778   Topic4   2783.143067            x80   2961.846853   2.0967  -5.5982\n",
       "281673   Topic4   2447.870929            xb8   2614.659009   2.0930  -5.7266\n",
       "125631   Topic4   1890.410526        gettext   2012.120308   2.0965  -5.9850\n",
       "118970   Topic4  25303.791250           from  35518.688459   1.8198  -3.3908\n",
       "159703   Topic4   3531.937969             m0   4032.249447   2.0265  -5.3600\n",
       "180274   Topic4  13905.857008        nimport  18618.241233   1.8671  -3.9895\n",
       "80335    Topic4   3754.111068        classes   4406.066269   1.9988  -5.2989\n",
       "256735   Topic4   4381.802305          theme   5290.645352   1.9704  -5.1443\n",
       "93741    Topic4  17418.249385        default  26333.112557   1.7456  -3.7643\n",
       "88232    Topic4   4506.570775  createelement   5809.050620   1.9050  -5.1163\n",
       "281915   Topic4   3107.373594            xe2   3715.416427   1.9802  -5.4880\n",
       "195902   Topic4  10511.869373           path  18062.283987   1.6176  -4.2693\n",
       "271947   Topic4   5130.621772          utils   7309.065558   1.8050  -4.9866\n",
       "205318   Topic4   5762.003143          props  10334.712205   1.5747  -4.8705\n",
       "139197   Topic4   8875.248415         import  26520.253223   1.0643  -4.4385\n",
       "72266    Topic4   3771.316901         button   5993.534881   1.6957  -5.2944\n",
       "58561    Topic4   6152.414621             as  16313.427580   1.1838  -4.8050\n",
       "98673    Topic4   4765.756502            div  11566.051403   1.2723  -5.0603\n",
       "113922   Topic4   3483.098034           fill   6022.766772   1.6113  -5.3739\n",
       "182715   Topic4   4964.224770           none  21713.103820   0.6833  -5.0195\n",
       "267055   Topic4   3281.604912             ui   7342.754502   1.3535  -5.4335\n",
       "\n",
       "[293 rows x 6 columns], token_table=        Topic      Freq          Term\n",
       "term                                 \n",
       "2713        2  0.000651  0h24v24h0v0z\n",
       "2713        4  0.999279  0h24v24h0v0z\n",
       "2718        4  0.998298    0h24v24h0z\n",
       "4646        1  0.109472            10\n",
       "4646        2  0.775334            10\n",
       "4646        3  0.053442            10\n",
       "4646        4  0.061747            10\n",
       "5507        1  0.022969            11\n",
       "5507        2  0.933162            11\n",
       "5507        3  0.009225            11\n",
       "5507        4  0.034685            11\n",
       "6203        1  0.015994            12\n",
       "6203        2  0.948063            12\n",
       "6203        3  0.006335            12\n",
       "6203        4  0.029651            12\n",
       "7684        1  0.013560            13\n",
       "7684        2  0.982352            13\n",
       "7684        3  0.003417            13\n",
       "7684        4  0.000772            13\n",
       "8196        1  0.026747            14\n",
       "8196        2  0.950212            14\n",
       "8196        3  0.022485            14\n",
       "8196        4  0.000639            14\n",
       "9620        1  0.050299            15\n",
       "9620        2  0.907928            15\n",
       "9620        3  0.035548            15\n",
       "9620        4  0.006167            15\n",
       "10108       1  0.028640            16\n",
       "10108       2  0.968768            16\n",
       "10108       4  0.002565            16\n",
       "...       ...       ...           ...\n",
       "281786      4  0.977867           xbf\n",
       "281809      1  0.019570           xc3\n",
       "281809      3  0.007561           xc3\n",
       "281809      4  0.973174           xc3\n",
       "281829      1  0.000826           xce\n",
       "281829      4  0.998334           xce\n",
       "281832      1  0.003657           xcf\n",
       "281832      4  0.996508           xcf\n",
       "281843      4  0.999894           xd0\n",
       "281844      4  0.999921           xd1\n",
       "281848      4  0.999018           xd5\n",
       "281850      1  0.001933           xd7\n",
       "281850      4  0.997517           xd7\n",
       "281852      1  0.000363           xd8\n",
       "281852      4  0.999268           xd8\n",
       "281853      4  0.999439           xd9\n",
       "281885      4  0.999894           xe0\n",
       "281886      1  0.000759           xe1\n",
       "281886      2  0.000506           xe1\n",
       "281886      4  0.998659           xe1\n",
       "281915      1  0.163642           xe2\n",
       "281915      4  0.836245           xe2\n",
       "281933      1  0.001972           xe6\n",
       "281933      4  0.996935           xe6\n",
       "281984      1  0.002128           xec\n",
       "281984      4  0.997862           xec\n",
       "284097      3  0.999757        zerver\n",
       "284640      1  0.072605         zulip\n",
       "284640      2  0.002936         zulip\n",
       "284640      3  0.924646         zulip\n",
       "\n",
       "[496 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[1, 4, 2, 3])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyLDAvis.sklearn.prepare(model, tf, tf_vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to do this on the full dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_languages = 4\n",
    "all_documents = full_dataset['documents']\n",
    "\n",
    "full_tf_vectorizer = CountVectorizer(stop_words=None)\n",
    "full_tf = full_tf_vectorizer.fit_transform(all_documents)\n",
    "full_tf_feature_names = full_tf_vectorizer.get_feature_names()\n",
    "\n",
    "full_lda = LatentDirichletAllocation(n_topics=number_of_languages,  n_jobs=1)\n",
    "full_model = full_lda.fit(full_tf)\n",
    "\n",
    "with open('../data/full_lda_model.pickle', 'wb') as f:\n",
    "    pickle.dump(full_model, f)\n",
    "\n",
    "with open('../data/full_tf.pickle', 'wb') as f:\n",
    "    pickle.dump(full_tf, f)\n",
    "    \n",
    "with open('../data/full_tf_vectorizer.pickle', 'wb') as f:\n",
    "    pickle.dump(full_tf_vectorizer, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/full_lda_model.pickle', 'rb') as f:\n",
    "    full_model = pickle.load(f)\n",
    "\n",
    "with open('../data/full_tf.pickle', 'rb') as f:\n",
    "    full_tf = pickle.load(f)\n",
    "    \n",
    "with open('../data/full_tf_vectorizer.pickle', 'rb') as f:\n",
    "    full_tf_vectorizer = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize our new model. Note that the following code cell requires more than 8 GB of RAM to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.sklearn.prepare(full_model, full_tf, full_tf_vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://nbviewer.jupyter.org/github/bmabey/pyLDAvis/blob/master/notebooks/sklearn.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modelling on Programming Language Mixtures\n",
    "Keypoint: topics are programming languages, file with mixture of programming languages, identify which is which.\n",
    "\n",
    "Applicability to cyber-security: identifying malware embedded within normal programs (shellcode)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining Source Files per Repository\n",
    "\n",
    "Currently our data set consists of one data point per file containing:\n",
    "  1. ID of the Github repository the file belongs to.\n",
    "  2. Programming language it is written in (identified by file extension).\n",
    "  3. File contents\n",
    "  \n",
    "In this section, we extend our analysis from working on documents with one language per file, to a system where there is a mixture of languages inside each document. To do this, we combine all the files in each repository into a single data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_texts(group):\n",
    "    [repo_id] = group['repo'].unique()\n",
    "    combined = ' '.join(group['documents'])\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_documents = minimal_dataset.groupby(by='repo').apply(concat_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "repo\n",
       "19438      b\"#' @include ggplot-global.R\\n#' @include ggp...\n",
       "26554      b'# The contents of this file are subject to t...\n",
       "544208     b'import logging\\nimport os\\nimport platform a...\n",
       "643909     b'#\\' Environment variables to set when callin...\n",
       "2594513    b'# S3 method to deal with chunks and inline t...\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_documents.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_vectorizer = CountVectorizer(stop_words=None)\n",
    "tf = tf_vectorizer.fit_transform(combined_documents)\n",
    "\n",
    "with open('../data/concatDocs_tf_vectorizer.pickle', 'wb') as f:\n",
    "    pickle.dump(tf_vectorizer, f)\n",
    "    \n",
    "with open('../data/concatDocs_tf.pickle', 'wb') as f:\n",
    "    pickle.dump(tf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_languages = 4\n",
    "\n",
    "lda = LatentDirichletAllocation(n_topics=number_of_languages,  n_jobs=1)\n",
    "model = lda.fit(tf)\n",
    "\n",
    "with open('../data/concatDocs_lda_model.pickle', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/concatDocs_lda_model.pickle', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "    \n",
    "with open('../data/concatDocs_tf.pickle', 'rb') as f:\n",
    "    tf = pickle.load(f)\n",
    "    \n",
    "with open('../data/concatDocs_tf_vectorizer.pickle', 'rb') as f:\n",
    "    tf_vectorizer = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.sklearn.prepare(model, tf, tf_vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying Program Subjects and Themes\n",
    "\n",
    "Hypothesis: Using tf-idf rather than bag-of-words as an input to LDA will prioritise rare words. In the case of source code, this means programming language keywords (an identifying feature of programming languages) are deprioritised, and so a more human idea of topics may emerge. \n",
    "\n",
    "We can use repo-list.json and the repo-ids to map the github topics/tags to each repo. Might be a small/easy task to compare against the programming langauge identification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = minimal_dataset['documents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_vectorizer = TfidfVectorizer(stop_words=None)\n",
    "tf = tf_vectorizer.fit_transform(documents)\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "\n",
    "with open('../data/tfidf_lda_tf.pickle', 'wb') as f:\n",
    "    pickle.dump(tf, f)\n",
    "    \n",
    "with open('../data/tfidf_lda_tf_vectorizer.pickle', 'wb') as f:\n",
    "    pickle.dump(tf_vectorizer, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have four programming languages, try to use LDA to determine these four programming languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sharding/miniconda3/envs/myenv/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:314: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "number_of_themes = 3\n",
    "\n",
    "lda = LatentDirichletAllocation(n_topics=number_of_themes,  n_jobs=1)\n",
    "model = lda.fit(tf)\n",
    "\n",
    "with open('../data/tfidf_lda_model.pickle', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/tfidf_lda_model.pickle', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "    \n",
    "with open('../data/tfidf_lda_tf.pickle', 'rb') as f:\n",
    "    tf = pickle.load(f)\n",
    "    \n",
    "with open('../data/tfidf_lda_tf_vectorizer.pickle', 'rb') as f:\n",
    "    tf_vectorizer = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pyLDAvis.sklearn.prepare(model, tf, tf_vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This still prioritises programming language keywords. One approach to solving this problem is to consider all keywords as \"stopwords\". First, gather a list of R, Python and Javascript keywords:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keyword\n",
    "\n",
    "python_keywords = keyword.kwlist\n",
    "python_keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R reserved words (sourced from the manual: https://stat.ethz.ch/R-manual/R-devel/library/base/html/Reserved.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_keywords = [\n",
    "    \"if\", \n",
    "    \"else\", \n",
    "    \"repeat\",\n",
    "    \"while\",\n",
    "    \"function\", \n",
    "    \"for\",\n",
    "    \"in\",\n",
    "    \"next\",\n",
    "    \"break\",\n",
    "    \"TRUE\",\n",
    "    \"FALSE\",\n",
    "    \"NULL\", \n",
    "    \"Inf\", \n",
    "    \"NaN\",\n",
    "    \"NA\",\n",
    "    \"NA_integer_\",\n",
    "    \"NA_real_\",\n",
    "    \"NA_complex_\",\n",
    "    \"NA_character_\", \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Javascript keywords and reserved words (source: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Lexical_grammar#Keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "javascript_keywords = [  # jaccard(\"ideal javascript topic\", topic_i)\n",
    "    \"break\",\n",
    "    \"case\",\n",
    "    \"catch\",\n",
    "    \"class\",\n",
    "    \"const\",\n",
    "    \"continue\",\n",
    "    \"debugger\",\n",
    "    \"default\",\n",
    "    \"delete\",\n",
    "    \"do\",\n",
    "    \"else\",\n",
    "    \"export\",\n",
    "    \"extends\",\n",
    "    \"finally\",\n",
    "    \"for\",\n",
    "    \"function\",\n",
    "    \"if\",\n",
    "    \"import\",\n",
    "    \"in\",\n",
    "    \"instanceof\",\n",
    "    \"new\",\n",
    "    \"return\",\n",
    "    \"super\",\n",
    "    \"switch\",\n",
    "    \"this\",\n",
    "    \"throw\",\n",
    "    \"try\",\n",
    "    \"typeof\",\n",
    "    \"var\",\n",
    "    \"void\",\n",
    "    \"while\",\n",
    "    \"with\",\n",
    "    \"yield\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = minimal_dataset['documents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_vectorizer = TfidfVectorizer(stop_words=javascript_keywords+python_keywords+r_keywords)\n",
    "tf = tf_vectorizer.fit_transform(documents)\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "    \n",
    "with open('../data/tfidf_lda_tf_ignore_keywords.pickle', 'rb') as f:\n",
    "    pickle.dump(tf, f)\n",
    "    \n",
    "with open('../data/tfidf_lda_tf_vectoriser_ignore_keywords.pickle', 'rb') as f:\n",
    "    pickle.dump(tf_vectoriser, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have four programming languages, try to use LDA to determine these four programming languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "number_of_themes = 3\n",
    "\n",
    "lda = LatentDirichletAllocation(n_topics=number_of_themes,  n_jobs=1)\n",
    "model = lda.fit(tf)\n",
    "\n",
    "with open('../data/tfidf_lda_model_ignore_keywords.pickle', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/tfidf_lda_model_ignore_keywords.pickle', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "    \n",
    "with open('../data/tfidf_lda_tf_ignore_keywords.pickle', 'rb') as f:\n",
    "    tf = pickle.load(f)\n",
    "    \n",
    "with open('../data/tfidf_lda_tf_vectoriser_ignore_keywords.pickle', 'rb') as f:\n",
    "    tf_vectoriser = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pyLDAvis.sklearn.prepare(model, tf, tf_vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring the Efficacy of Topic Models (WRITEUP: WHO?)\n",
    "\n",
    "Main question: How do we evaluate how well a topic (from LDA for example) represents a meaningful \"topic\" or theme?\n",
    "\n",
    "TODO: do some research on this??? There must be some papers etc that try to formalise this that we can borrow ideas from?\n",
    "\n",
    "Paper dump:\n",
    "  - Looks like a good summary paper: http://www.aclweb.org/anthology/E14-4005 Find more papers from this ones references?\n",
    "    - \" KL-divergence (Li and McCallum, 2006; Wang et al., 2009; Newman et al., 2009), cosine measure (He et al., 2009; Ramage et al., 2009) and the average Log Odds Ratio (Chaney and Blei, 2012). \"\n",
    "    - \"Kim and Oh (2011) also applied  the  cosine  measure  and  KL-Divergence which were compared with four other measures: Jaccards Coefficient, Kendalls  coefficient, Discount  Cumulative  Gain  and  Jensen  Shannon  Divergence (JSD).\"\n",
    "  - Cool name haven't read it: http://papers.nips.cc/paper/3700-reading-tea-leaves-how-humans-interpret-topic-models.pdf\n",
    "  \n",
    "We considered all of these metrics, and found th Jaccard Index to be most suitable. This was primarily due to it's use of set operations, which are invariant to ordering and number of observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Tea Leaves Paper\n",
    "http://papers.nips.cc/paper/3700-reading-tea-leaves-how-humans-interpret-topic-models.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Overlap\n",
    "\n",
    "I think this is used as a baseline measure in the summary paper above (http://www.aclweb.org/anthology/E14-4005). Should be a quick implementation so worth a try."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jaccard Index\n",
    "\n",
    "From the papers above this seems to have been used relatively often for _linking machine-generated topics to human topics_ and so maybe this is a good application for it. Apparently explored here \"https://link.springer.com/chapter/10.1007/978-3-642-19437-5_13\" but I haven't read it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_index(a, b):\n",
    "    a = set(a)\n",
    "    b = set(b)\n",
    "    return len(a & b) / len(a | b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the group of language keywords as the best possible topic for each language. Compare each of our machine generated topics with each of our ideal topics by computing their Jaccard Index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_vectorizer = CountVectorizer(stop_words=None)\n",
    "tf = tf_vectorizer.fit_transform(documents)\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tf_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(enumerate(model.components_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kendalls  Coefficient\n",
    "\n",
    "Measures the association between two ranked lists. Source: Computational Linguistics and Intelligent Text Processing book."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Topic Models\n",
    "TODO: better title needed\n",
    "\n",
    "Idea:\n",
    "  - save the actual % of each program langauge per repo\n",
    "  - Then try to use LDA model to tell us \"I believe repo <x> is 10% Topic 1, 20% Topic 2 etc\". \n",
    "  - Use analysis from above two sections to create a \"most likely mapping from lda topic to programming language\".\n",
    "  - rate our models\n",
    "\n",
    "Here we can do cross-validation etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in the test data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = pandas.read_csv(\"../data/test-dataset.csv.gz\", header=None, names=['repo', 'language', 'topics', 'documents'])\n",
    "\n",
    "# Remove Github 'topics' since we don't use them in this analysis\n",
    "test_dataset = test_dataset.drop(columns='topics')\n",
    "\n",
    "test_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the mixture model, we must label each repository with it's percentage of each programming language:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_language_percentages(group):\n",
    "    total_python_length = 0\n",
    "    total_r_length = 0\n",
    "    total_javascript_length = 0\n",
    "    \n",
    "    for index, repo, language, document in group.itertuples():\n",
    "        if language == 'python':\n",
    "            total_python_length += len(document)\n",
    "            \n",
    "        if language == 'javascript':\n",
    "            total_javascript_length += len(document)\n",
    "            \n",
    "        if language == 'r':\n",
    "            total_r_length += len(document)\n",
    "            \n",
    "    total_length = total_python_length + total_r_length + total_javascript_length\n",
    "            \n",
    "    return pandas.Series([\n",
    "        total_python_length/total_length,\n",
    "        total_r_length/total_length,\n",
    "        total_javascript_length/total_length,\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_composition_actual = test_dataset.groupby(by='repo').apply(calculate_language_percentages)\n",
    "test_composition_actual.columns = ['python', 'r', 'javascript']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the programming language percentages for each of repository in our test dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_composition_actual.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KL Divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_composition_estim=test_composition_actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if all(test_composition_estim.index==test_composition_actual.index)==True:\n",
    "    KDDataframe=pandas.DataFrame([],columns=[\"Repo\",\"KD Divergence\"])\n",
    "    for i in range(0,len(test_composition_actual)):\n",
    "        a=0\n",
    "        for j in range(0,len(test_composition_actual.iloc[i])):\n",
    "            a=a-((test_composition_actual.iloc[i][j])*math.log(test_composition_actual.iloc[i][j]/test_composition_estim.iloc[i][j]))\n",
    "        #m=pandas.DataFrame([test_composition_actual.index[i],a],columns=[\"Repo\",\"KD Divergence\"])\n",
    "        print(a)\n",
    "        #KDDataframe.append(m)\n",
    "#KDDataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes:\n",
    "  - our keyword lists have simliar/common words e.g. python javascript and r all share some keywords. this can be seen in the documents. choosing another language, with a completely different set of keywords might prove easier to differentiate for the LDA model. somethind somthing LDA uses distance, but if true topics share key words, then distance metric breaks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
