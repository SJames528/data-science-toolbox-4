{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modelling on Program Source Code\n",
    "---\n",
    "By Kishalay Banerjee, Dan Jones and Sam Harding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # 0y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import pickle\n",
    "import numpy\n",
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "pyLDAvis.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "from urllib.request import urlretrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.random.seed(0xD00D5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "\n",
    "There are a number of files which are too large to store on GitHub. These are hosted on our server, and can be downloaded by running the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\n",
    "    'full_lda_model.pickle',\n",
    "    'full_tf.pickle',\n",
    "    'full_tf_vectorizer.pickle',\n",
    "    'full-dataset.csv.gz',\n",
    "]\n",
    "\n",
    "base_url = 'https://daniel.wilshirejones.com/private-uUX6IzfsRYLNiti4ZFmgv6U3dFInnq37r5YSQs46iejeB96q0MAy9Ko7hkgo/'\n",
    "destination_directory = '../data/'\n",
    "\n",
    "for file in files:\n",
    "    url = base_url + file\n",
    "    destination = destination_directory + file\n",
    "    print(\"Downloading '{}'' to location '{}'\".format(url, destination))\n",
    "    urlretrieve(url, destination)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating the Dataset\n",
    "\n",
    "TODO: Import dataset.py and explain how it's used + what it does.\n",
    "\n",
    "TODO: Add Sam's scrub function in here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>language</th>\n",
       "      <th>documents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28457823</td>\n",
       "      <td>javascript</td>\n",
       "      <td>b\"module.exports = {\\n  plugins: [\\n    requir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28457823</td>\n",
       "      <td>javascript</td>\n",
       "      <td>b\"// The path where to mount the REST API app\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28457823</td>\n",
       "      <td>javascript</td>\n",
       "      <td>b\"import { Observable } from 'rx';\\nimport deb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28457823</td>\n",
       "      <td>javascript</td>\n",
       "      <td>b\"import { Observable } from 'rx';\\n// import ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28457823</td>\n",
       "      <td>javascript</td>\n",
       "      <td>b\"import { Observable } from 'rx';\\n\\nmodule.e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       repo    language                                          documents\n",
       "0  28457823  javascript  b\"module.exports = {\\n  plugins: [\\n    requir...\n",
       "1  28457823  javascript  b\"// The path where to mount the REST API app\\...\n",
       "2  28457823  javascript  b\"import { Observable } from 'rx';\\nimport deb...\n",
       "3  28457823  javascript  b\"import { Observable } from 'rx';\\n// import ...\n",
       "4  28457823  javascript  b\"import { Observable } from 'rx';\\n\\nmodule.e..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minimal_dataset = pandas.read_csv(\"../data/dataset.csv.gz\", header=None, names=['repo', 'language', 'documents'])\n",
    "minimal_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = pandas.read_csv(\"../data/full-dataset.csv.gz\", header=None, names=['repo', 'language',  'topics', 'documents'])\n",
    "\n",
    "# Remove Github 'topics' since we don't use them in this analysis\n",
    "full_dataset = full_dataset.drop(columns='topics')\n",
    "\n",
    "full_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modelling on Individual Source Files\n",
    "\n",
    "Basically done, just need to copy it over. Maybe run on the bigger dataset?\n",
    "\n",
    "TODO:\n",
    "  - Copy work from documentation/daniel-jones.ipynb\n",
    "  - Add visualisation with pyldavis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our purposes, common words are important and rare words aren't. So we shouldn't use tf-idf as a metric, bag-of-words makes more sense. (TODO: Maybe: \"Similarly, filter out words that don't occur very often\").\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = minimal_dataset['documents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_vectorizer = CountVectorizer(stop_words=None)\n",
    "tf = tf_vectorizer.fit_transform(documents)\n",
    "\n",
    "with open('../data/minimal_lda_tf.pickle', 'wb') as f:\n",
    "    pickle.dump(tf, f)\n",
    "    \n",
    "with open('../data/minimal_lda_tf_vectorizer.pickle', 'wb') as f:\n",
    "    pickle.dump(tf_vectorizer, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have four programming languages, try to use LDA to determine these four programming languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_languages = 4\n",
    "\n",
    "lda = LatentDirichletAllocation(n_topics=number_of_languages,  n_jobs=1)\n",
    "model = lda.fit(tf)\n",
    "\n",
    "with open('../data/minimal_lda_model.pickle', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/minimal_lda_model.pickle', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "    \n",
    "with open('../data/minimal_lda_tf.pickle', 'rb') as f:\n",
    "    tf = pickle.load(f)\n",
    "    \n",
    "with open('../data/minimal_lda_tf_vectorizer.pickle', 'rb') as f:\n",
    "    tf_vectorizer = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.sklearn.prepare(model, tf, tf_vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to do this on the full dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_languages = 4\n",
    "all_documents = full_dataset['documents']\n",
    "\n",
    "full_tf_vectorizer = CountVectorizer(stop_words=None)\n",
    "full_tf = full_tf_vectorizer.fit_transform(all_documents)\n",
    "full_tf_feature_names = full_tf_vectorizer.get_feature_names()\n",
    "\n",
    "full_lda = LatentDirichletAllocation(n_topics=number_of_languages,  n_jobs=1)\n",
    "full_model = full_lda.fit(full_tf)\n",
    "\n",
    "with open('../data/full_lda_model.pickle', 'wb') as f:\n",
    "    pickle.dump(full_model, f)\n",
    "\n",
    "with open('../data/full_tf.pickle', 'wb') as f:\n",
    "    pickle.dump(full_tf, f)\n",
    "    \n",
    "with open('../data/full_tf_vectorizer.pickle', 'wb') as f:\n",
    "    pickle.dump(full_tf_vectorizer, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/full_lda_model.pickle', 'rb') as f:\n",
    "    full_model = pickle.load(f)\n",
    "\n",
    "with open('../data/full_tf.pickle', 'rb') as f:\n",
    "    full_tf = pickle.load(f)\n",
    "    \n",
    "with open('../data/full_tf_vectorizer.pickle', 'rb') as f:\n",
    "    full_tf_vectorizer = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize our new model. Note that the following code cell requires more than 8 GB of RAM to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.sklearn.prepare(full_model, full_tf, full_tf_vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://nbviewer.jupyter.org/github/bmabey/pyLDAvis/blob/master/notebooks/sklearn.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modelling on Programming Language Mixtures\n",
    "Keypoint: topics are programming languages, file with mixture of programming languages, identify which is which.\n",
    "\n",
    "Applicability to cyber-security: identifying malware embedded within normal programs (shellcode)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining Source Files per Repository\n",
    "\n",
    "Currently our data set consists of one data point per file containing:\n",
    "  1. ID of the Github repository the file belongs to.\n",
    "  2. Programming language it is written in (identified by file extension).\n",
    "  3. File contents\n",
    "  \n",
    "In this section, we extend our analysis from working on documents with one language per file, to a system where there is a mixture of languages inside each document. To do this, we combine all the files in each repository into a single data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_texts(group):\n",
    "    [repo_id] = group['repo'].unique()\n",
    "    combined = ' '.join(group['documents'])\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_documents = minimal_dataset.groupby(by='repo').apply(concat_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "repo\n",
       "19438      b\"#' @include ggplot-global.R\\n#' @include ggp...\n",
       "26554      b'# The contents of this file are subject to t...\n",
       "544208     b'import logging\\nimport os\\nimport platform a...\n",
       "643909     b'#\\' Environment variables to set when callin...\n",
       "2594513    b'# S3 method to deal with chunks and inline t...\n",
       "dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_documents.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_vectorizer = CountVectorizer(stop_words=None)\n",
    "tf = tf_vectorizer.fit_transform(combined_documents)\n",
    "\n",
    "with open('../data/concatDocs_tf_vectorizer.pickle', 'wb') as f:\n",
    "    pickle.dump(tf_vectorizer, f)\n",
    "    \n",
    "with open('../data/concatDocs_tf.pickle', 'wb') as f:\n",
    "    pickle.dump(tf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dan/.guix-profile/lib/python3.7/site-packages/sklearn/decomposition/online_lda.py:314: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "number_of_languages = 4\n",
    "\n",
    "lda = LatentDirichletAllocation(n_topics=number_of_languages,  n_jobs=1)\n",
    "model = lda.fit(tf)\n",
    "\n",
    "with open('../data/concatDocs_lda_model.pickle', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/concatDocs_lda_model.pickle', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "    \n",
    "with open('../data/concatDocs_tf.pickle', 'rb') as f:\n",
    "    tf = pickle.load(f)\n",
    "    \n",
    "with open('../data/concatDocs_tf_vectorizer.pickle', 'rb') as f:\n",
    "    tf_vectorizer = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el100081396561175280408114403987\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el100081396561175280408114403987_data = {\"mdsDat\": {\"x\": [0.15097313194226245, -0.016624928891155116, -0.3021641883248733, 0.1678159852737662], \"y\": [-0.0006136346267290705, -0.16787658812324502, 0.06590415612895145, 0.10258606662102275], \"topics\": [1, 2, 3, 4], \"cluster\": [1, 1, 1, 1], \"Freq\": [49.04175989229053, 24.72361074214987, 13.224716429621916, 13.009912935937692]}, \"tinfo\": {\"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\"], \"Freq\": [74181.0, 35155.0, 23585.0, 17361.0, 39038.0, 13050.0, 14728.0, 18154.0, 11576.0, 11270.0, 70622.0, 15211.0, 11369.0, 26488.0, 12663.0, 9799.0, 10783.0, 21424.0, 9429.0, 10829.0, 8399.0, 20970.0, 33744.0, 6988.0, 5677.0, 9610.0, 74472.0, 5366.0, 7050.0, 11499.0, 5800.137466136051, 1746.1512931026878, 1428.4456120445209, 1364.1121016881812, 2365.125909641698, 1171.1071722755373, 1118.6550067983073, 1110.7373459042585, 2450.8333455180677, 992.9588688188968, 943.470319215259, 842.516601917129, 812.8243658593833, 795.0070356853743, 766.3016223155237, 705.9337140371474, 669.3118612095249, 663.3681286408088, 647.5368792954251, 641.6004628471959, 641.5993969829482, 634.6707132978363, 611.9068685783294, 560.4412065483465, 555.4884438670781, 543.614906630401, 527.7785419623957, 524.8082390118728, 521.8403591618415, 518.8719919098717, 3464.28226093068, 2998.464977770598, 1622.4344226912795, 1992.5986349045827, 2320.4495104352964, 1117.1821017853297, 927.6305776964886, 726.8333144591355, 1509.8764238695692, 2662.3323588826006, 2071.683471329658, 4039.3578186467444, 1327.2475267570685, 915.4345203439424, 1060.0973436330592, 6947.610727902088, 1953.486091439043, 1452.8156954663657, 1293.956253810379, 2055.442427726426, 2936.951422956756, 1752.3402365789084, 5323.5552710853435, 5005.691943891331, 8278.401012892724, 54091.98092478069, 18605.455650643828, 2554.2140941140337, 5224.104357553589, 55257.00216898386, 64094.19847428494, 15299.243611672287, 26534.717650871902, 8635.263204458208, 15777.128068979773, 52244.02117842156, 19185.61248069426, 33976.15954235694, 22028.193181605504, 12059.669419994045, 24435.504252186907, 49420.78997213291, 27193.899879811794, 16451.160341835533, 8103.652817856177, 12619.954381225882, 9027.530381201874, 6211.910247569658, 15230.26999197813, 21036.39996348479, 15730.755862004384, 8461.841574222319, 33726.933324773505, 9966.949786799247, 12607.299849538507, 11943.889560285781, 10399.809628472587, 11390.90794321126, 9809.51914816114, 9149.288342370688, 9064.470246239163, 14728.039319861717, 3716.965779416397, 2792.0120400930637, 1015.4255956817979, 953.3864769116087, 830.2483799846483, 773.8480579698962, 717.4483294256671, 597.1302765252212, 520.9898718983236, 519.1108891356915, 487.1511400843681, 5029.180731690747, 382.8109567153772, 1797.5008545957958, 347.0922398277909, 341.45228411264435, 335.81232839748463, 333.9313404261886, 322.6524317287239, 319.8314511066192, 1265.2670283852763, 302.9125867254206, 296.3326383909371, 294.45265315250833, 292.5726679140773, 289.7526900564264, 277.53075666605855, 270.0128450527102, 270.0128450527102, 34233.79806450686, 2874.645087057754, 929.7391921942582, 1726.3525132469488, 474.9179338952394, 10374.067551297509, 5369.729014145358, 14238.677342698846, 1726.9579189443732, 4582.176379123825, 524.7418868920779, 905.3938566720906, 5959.762925945653, 697.6719389206281, 8077.59987112565, 4794.268485898471, 3844.8791993956734, 5601.086914296464, 29234.92484084435, 1444.1767433256755, 1722.0887122833642, 15577.273460553877, 9301.610633455492, 18691.077615775706, 4722.615832709708, 2662.7757563155187, 1743.7755704673789, 6242.697632836929, 13072.91755057849, 6862.024896549475, 4685.958106825996, 4732.507010174554, 2898.7951559242106, 4107.0374374668945, 11308.478279721598, 8148.750458746417, 4288.905527496331, 4672.1953170485995, 10499.97453242758, 20362.218303455506, 16035.125129686232, 14537.740828865888, 14441.563685624147, 6717.259997300647, 4894.0590891960255, 5906.795874150945, 8260.588730030286, 5917.4789696510325, 5807.2279770905325, 6487.468897639491, 5014.133383606465, 5399.959272428444, 5314.163111080996, 2379.4146143956013, 2300.7107676603246, 1933.7745845090656, 1390.2218113224758, 1408.516226226317, 530.9697822113337, 487.04681609312274, 456.84867791327594, 450.4439553251391, 443.1192765588591, 425.7331724416855, 413.83348694588534, 364.41963289154245, 351.61623125158303, 354.34934204380176, 347.9559451747847, 346.11820511877346, 311.353084406801, 702.9913246575501, 302.1947690354682, 303.10366120149524, 271.08993756201886, 271.08993756201886, 269.25219613996074, 419.8369070491946, 259.1768016526174, 249.1282211012286, 241.80764894763183, 448.01967354934965, 236.31621203874377, 5653.882341513981, 2927.541982991441, 1323.933149635821, 1769.0615221387804, 1983.735577744266, 507.1706015102195, 1645.146074894184, 942.1634600387509, 642.6074916656358, 613.0848729741998, 638.9930624670064, 493.8828884162312, 14662.996249915277, 9929.759933884814, 10888.523617167863, 9289.261077991983, 5909.899005160007, 18242.502203037977, 865.8814630404819, 7742.315463902279, 2135.4118100151313, 5460.3902009516105, 4149.978586732626, 8233.273009589815, 6926.175546650544, 7802.564816267143, 3028.6815774809625, 8285.755297687896, 4860.37466511722, 3894.2177513197016, 4537.825432154131, 10678.159853304287, 5071.41561036076, 5223.651362238425, 4898.996322824103, 6062.24392383903, 3607.342611314222, 3859.705456368823, 4429.36629183236, 3706.1674034710136, 3148.1786146466598, 3562.6497560444373, 3308.1498345048785, 4014.096844794307, 3358.6831653970025, 3157.1575533260734, 1885.141710461193, 1386.8752271066726, 1037.4409089286396, 1042.059380762214, 1033.7430247532363, 1023.5744677310986, 958.8644088092403, 857.1749967160251, 733.3036319959068, 725.9056091152271, 713.8906143193493, 654.7271318765075, 605.7323729785294, 600.185796499513, 574.3017729307696, 564.1330493859065, 558.58647290689, 558.5830649550828, 509.59171400891177, 502.1962787035564, 500.34741987721776, 459.672525697764, 453.2015198055782, 451.35266097923954, 438.4106491948678, 429.1663550631738, 382.9448844047037, 5349.887422257279, 1525.1342791892253, 907.8370549363361, 857.1772900102482, 1370.983856861816, 601.9740328270552, 843.3108457188291, 4390.3876608401815, 1715.5296172383037, 5942.681017586625, 870.6925624768512, 1042.1445882775513, 4265.102734402547, 2262.47902055655, 1663.199723032858, 1043.602860606315, 24409.02858811899, 4817.8578553135485, 5456.608823057205, 2718.5273318955774, 3665.434448550517, 7077.002441058161, 1637.3756948905557, 3051.074423773889, 4631.711733535563, 2626.3814847475364, 4786.163104383402, 9544.348309248177, 4171.843619779558, 9379.984936310066, 6228.7567623769255, 6316.713181522725, 4336.589340891188, 6632.025491143102, 8141.64966641196, 4688.213274334474, 5205.97025820362, 4869.969296153803, 3783.7459500345017, 6334.812397658502, 4521.120574968868, 3931.270273452493, 3768.163632863365, 4428.481625576538, 3654.778962099757], \"Term\": [\"self\", \"react\", \"12\", \"16\", \"from\", \"24\", \"createsvgicon\", \"10\", \"32\", \"48\", \"the\", \"nexport\", \"14\", \"default\", \"11\", \"21\", \"13\", \"none\", \"17\", \"fragment\", \"str\", \"nimport\", \"in\", \"26\", \"512\", \"15\", \"if\", \"realm\", \"28\", \"message\", \"bokeh\", \"aes\", \"subreddit\", \"shiny\", \"tthis\", \"inst\", \"graphene\", \"ggplot\", \"np\", \"mobx\", \"valtype\", \"edittype\", \"plots\", \"gl\", \"ma\", \"columndatasource\", \"voucher\", \"redash\", \"ea\", \"_dereq_\", \"pgettext_lazy\", \"dflt\", \"ha\", \"anaconda\", \"geom_point\", \"saleor\", \"vec4\", \"aj\", \"xa\", \"plotting\", \"plot\", \"na\", \"r2\", \"reddit\", \"product\", \"classmethod\", \"kw\", \"rdname\", \"axis\", \"cls\", \"imports\", \"tobe\", \"figure\", \"ca\", \"datepicker\", \"license\", \"inc\", \"sr\", \"collection\", \"thing\", \"el\", \"pytest\", \"math\", \"tif\", \"code\", \"the\", \"of\", \"df\", \"param\", \"if\", \"this\", \"length\", \"for\", \"expect\", \"and\", \"function\", \"data\", \"var\", \"is\", \"else\", \"in\", \"return\", \"to\", \"null\", \"or\", \"not\", \"be\", \"source\", \"value\", \"true\", \"name\", \"options\", \"self\", \"new\", \"false\", \"def\", \"type\", \"import\", \"assert\", \"nfrom\", \"it\", \"createsvgicon\", \"0h24v24h0v0z\", \"misago\", \"withstyles\", \"api_link\", \"0h24v24h0z\", \"snackbar\", \"user_acl\", \"markdowndocs\", \"patch_category_acl\", \"m19\", \"iconbutton\", \"material\", \"other_thread\", \"typography\", \"listitemtext\", \"2v5c0\", \"2v14c0\", \"assertcontains\", \"2h14c1\", \"best_answer\", \"storybook\", \"handleclose\", \"activestep\", \"appbar\", \"12s4\", \"9959\", \"auc\", \"reqsource\", \"childat\", \"react\", \"strictequal\", \"testutils\", \"mount\", \"dddd\", \"fragment\", \"thread\", \"nexport\", \"gettext\", \"m0\", \"m20\", \"m12\", \"xe0\", \"2zm0\", \"classname\", \"classes\", \"wrapper\", \"createelement\", \"from\", \"threads\", \"onclick\", \"nimport\", \"props\", \"default\", \"proptypes\", \"styles\", \"xa4\", \"utils\", \"path\", \"45\", \"fill\", \"55\", \"xe2\", \"theme\", \"const\", \"div\", \"post\", \"component\", \"import\", \"this\", \"self\", \"return\", \"function\", \"as\", \"ui\", \"user\", \"if\", \"value\", \"none\", \"the\", \"response\", \"true\", \"var\", \"627\", \"__webpack_require__\", \"745\", \"837\", \"iana\", \"576\", \"40c0\", \"686\", \"12h40c6\", \"857\", \"971\", \"_interoprequiredefault\", \"_asynctogenerator2\", \"40c\", \"expect_hybrid\", \"12v40c0\", \"memberof\", \"256c0\", \"packrat\", \"_load_asynctogenerator\", \"funs\", \"48h352c26\", \"48v80c0\", \"_fs\", \"673\", \"oncompleted\", \"80v352c0\", \"32s14\", \"iteratee\", \"714\", \"512\", \"373\", \"448\", \"163\", \"248\", \"museum\", \"jp\", \"vnd\", \"327\", \"12v\", \"384\", \"496\", \"16\", \"32\", \"24\", \"48\", \"26\", \"12\", \"reporter\", \"21\", \"80\", \"28\", \"64\", \"14\", \"17\", \"13\", \"40\", \"11\", \"19\", \"23\", \"33\", \"10\", \"20\", \"22\", \"18\", \"15\", \"27\", \"35\", \"25\", \"29\", \"49\", \"31\", \"true\", \"user_profile\", \"zulip\", \"zerver\", \"hamlet\", \"stream_id\", \"stream_name\", \"expected_message\", \"example_email\", \"canonical_name\", \"example_user\", \"casper\", \"page_params\", \"cordelia\", \"ujson\", \"expected_topic\", \"realm_id\", \"assert_json_success\", \"nrun_test\", \"get_realm\", \"client_post\", \"othello\", \"send_and_test_stream_message\", \"stream_data\", \"blueslip\", \"assert_json_error\", \"topic_name\", \"iago\", \"client_get\", \"nset_global\", \"nzrequire\", \"realm\", \"userprofile\", \"full_name\", \"bot\", \"topic\", \"operand\", \"message_id\", \"stream\", \"user_id\", \"str\", \"streams\", \"aliases\", \"email\", \"equal\", \"payload\", \"recipient\", \"self\", \"result\", \"message\", \"dict\", \"assertequal\", \"none\", \"messages\", \"com\", \"id\", \"any\", \"def\", \"the\", \"nfrom\", \"if\", \"in\", \"to\", \"assert\", \"var\", \"return\", \"import\", \"for\", \"is\", \"user\", \"function\", \"true\", \"name\", \"false\", \"this\", \"data\"], \"Total\": [74181.0, 35155.0, 23585.0, 17361.0, 39038.0, 13050.0, 14728.0, 18154.0, 11576.0, 11270.0, 70622.0, 15211.0, 11369.0, 26488.0, 12663.0, 9799.0, 10783.0, 21424.0, 9429.0, 10829.0, 8399.0, 20970.0, 33744.0, 6988.0, 5677.0, 9610.0, 74472.0, 5366.0, 7050.0, 11499.0, 5800.832339529679, 1746.8476822484627, 1429.1404854360198, 1364.807218651795, 2366.3959509355464, 1171.8072014787929, 1119.3510574286004, 1111.4331411110595, 2452.467693761431, 993.6538529752454, 944.1666285081037, 843.212911249382, 813.5206520265673, 795.7051774956273, 767.0025045552018, 706.6285874307775, 670.0080348883749, 664.0692276188923, 648.2336563536991, 642.2953362386958, 642.2952659024974, 635.3670227706912, 612.602966783703, 561.1364460791729, 556.1875231418508, 544.3107756201358, 528.4748515496445, 525.5055657525534, 522.5364182865843, 519.5672663797228, 3469.658416759072, 3019.0533581285094, 1626.827649254445, 2004.274464695275, 2346.0299501639097, 1122.0271803680205, 930.1793764782718, 728.3369250062109, 1524.3104337133962, 2721.3048130715897, 2107.8856053795716, 4183.713264404739, 1343.8835703508876, 920.150587362483, 1069.360924336998, 7305.180202321204, 1997.165536777259, 1475.8772931878184, 1313.8905322667258, 2117.640847508411, 3082.015414301681, 1802.6183183567275, 5777.294193864276, 5443.773081337417, 9285.072982774162, 70622.70488741976, 22810.98772026065, 2710.3360527845125, 5869.481374045449, 74472.96522025249, 90254.69007344115, 19062.670912824142, 34934.67920916138, 10292.99688893563, 20077.237742860492, 74874.66472993894, 24983.359785431046, 47181.59634815673, 29838.229811890444, 15249.5181217259, 33744.52133401589, 74886.56812303525, 38579.398375982, 21874.276329356686, 10194.992072297135, 17435.40339826734, 11744.202433312514, 7600.408365727839, 22756.995390617703, 34265.62964538698, 23987.460395508482, 11138.589192226053, 74181.4428747312, 14171.35851368393, 20137.076596730036, 19234.092839187975, 16693.40721468156, 26791.663634590255, 19049.517445177775, 15317.673429399933, 14960.777154126636, 14728.746664515907, 3717.673124072188, 2792.7204355950244, 1016.1343452929236, 954.0948725921705, 830.9557942427098, 774.5562739992885, 718.1567251954482, 597.8376211922049, 521.6982678040894, 519.8182338046802, 487.85848475436376, 5038.166824940651, 383.51935280046564, 1800.98148479131, 347.79958450438806, 342.15962878962085, 336.51967307485336, 334.63973661027836, 323.3597764070609, 320.5398473248961, 1268.1622684917763, 303.61993140536805, 297.03998307146907, 295.15999783321206, 293.28001259495505, 290.4600347375694, 278.2402129510354, 270.72018973586546, 270.72018973586546, 35155.83325667956, 2914.8431442890005, 932.5803511696745, 1758.1085986440573, 477.4872846535669, 10829.339791952823, 5612.208032357692, 15211.436273373734, 1774.0825414824353, 4808.974334724756, 529.1182408757489, 923.9914461398776, 6413.346690345762, 713.0569823615863, 8965.135000990073, 5278.084185462462, 4356.508397315886, 6556.149365035924, 39038.312098514165, 1558.0619655144042, 1884.396137346552, 20970.803903269167, 12148.346562481109, 26488.640505401614, 5757.458919880845, 3083.525861580591, 1919.9525206858616, 8221.375025916597, 19686.16862053555, 9474.452606530913, 6164.30432000687, 6453.795788786785, 3568.1458338007224, 5542.0617814207335, 20592.58126242479, 13778.87156957697, 5952.763308451866, 7177.447470244102, 26791.663634590255, 90254.69007344115, 74181.4428747312, 74886.56812303525, 74874.66472993894, 15831.301902286887, 8018.581850932017, 16937.188373423418, 74472.96522025249, 22756.995390617703, 21424.371679385877, 70622.70488741976, 9673.50469091654, 34265.62964538698, 47181.59634815673, 2380.128267325872, 2301.4327446828665, 1934.4884537988353, 1390.9359951223805, 1410.162430014959, 531.6838281965881, 487.76035718338926, 457.56306053915057, 451.15749641540566, 443.83719659900254, 426.45087971294464, 414.55525643609644, 365.1413937479433, 352.32977234184966, 355.0759745779963, 348.6694862650513, 346.83996315087285, 312.06662549706766, 704.658313994111, 302.9165304872925, 303.83210624712973, 271.8034786522856, 271.8034786522856, 269.97395564957793, 420.99356726822435, 259.90895294284877, 249.84176219149543, 242.52119003789866, 449.3439466794883, 237.03084315966794, 5677.208696495247, 2943.296577097307, 1331.0110967205255, 1788.575854594989, 2015.877141987595, 508.8326298750743, 1670.8127265385708, 958.2868947813024, 654.6033936475043, 624.3867311830292, 652.0022223103771, 501.0336509891093, 17361.734648588317, 11576.52193369911, 13050.403131678364, 11270.625661630824, 6988.253532143485, 23585.89983572688, 914.5075708724463, 9799.347428622883, 2478.8712606435756, 7050.26802196004, 5283.428964042161, 11369.857213109552, 9429.995024991456, 10783.468005051598, 3732.9771678345223, 12663.77914222865, 6825.050078086913, 5287.478237934526, 6340.6924482175855, 18154.47228226275, 7322.122070827356, 7745.578567897239, 7232.826155836804, 9610.697722246652, 4908.137447343295, 5557.473977507569, 7144.53256112778, 5391.891037667988, 4252.736891668049, 5500.917298325384, 34265.62964538698, 4014.814954867141, 3359.394367013631, 3157.868754942702, 1885.8539019923091, 1387.5864287233012, 1038.1521105452682, 1042.7743312125956, 1034.4544046577623, 1024.2856693477272, 959.575610425869, 857.8884187375421, 734.0148336125354, 726.6194502731021, 714.6018159359779, 655.4383334931363, 606.4435745951581, 600.8969981161417, 575.0129745473984, 564.8442510025352, 559.2976745235187, 559.2977428194376, 510.3029156255405, 502.90748032018513, 501.0586214938465, 460.3837273143928, 453.91272142220697, 452.06386259586833, 439.1218508114966, 429.8775566798026, 383.65608602133256, 5366.058955752915, 1529.2450825082399, 919.6307960699244, 867.7855002128414, 1409.4159441921292, 607.6983747028775, 861.8372823212746, 5045.963201353814, 1949.0241137730268, 8399.383792531662, 937.1716596075217, 1159.751786515176, 6279.083909834781, 3186.636538134035, 2185.427400802366, 1224.776578500531, 74181.4428747312, 9477.672065169212, 11499.13873494548, 4715.041344475756, 7703.16634377942, 21424.371679385877, 2481.306966663158, 7003.838821977742, 16570.732969780387, 6292.078535735227, 19234.092839187975, 70622.70488741976, 15317.673429399933, 74472.96522025249, 33744.52133401589, 38579.398375982, 19049.517445177775, 47181.59634815673, 74886.56812303525, 26791.663634590255, 34934.67920916138, 29838.229811890444, 16937.188373423418, 74874.66472993894, 34265.62964538698, 23987.460395508482, 20137.076596730036, 90254.69007344115, 24983.359785431046], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.7124, 0.7121, 0.712, 0.712, 0.712, 0.7119, 0.7119, 0.7119, 0.7118, 0.7118, 0.7118, 0.7117, 0.7116, 0.7116, 0.7116, 0.7115, 0.7115, 0.7114, 0.7114, 0.7114, 0.7114, 0.7114, 0.7114, 0.7113, 0.7112, 0.7112, 0.7112, 0.7112, 0.7112, 0.7112, 0.7109, 0.7057, 0.7098, 0.7067, 0.7015, 0.7082, 0.7098, 0.7104, 0.703, 0.6906, 0.6952, 0.6774, 0.7, 0.7074, 0.7038, 0.6623, 0.6904, 0.6967, 0.6972, 0.6827, 0.6643, 0.6842, 0.6307, 0.6286, 0.5977, 0.4458, 0.5087, 0.6532, 0.596, 0.4141, 0.3702, 0.4926, 0.4375, 0.5369, 0.4715, 0.3526, 0.4484, 0.3842, 0.409, 0.4778, 0.3897, 0.2969, 0.3628, 0.4276, 0.4829, 0.3893, 0.4494, 0.5108, 0.3109, 0.2246, 0.2906, 0.4376, -0.0757, 0.3605, 0.2442, 0.236, 0.2393, -0.1428, 0.0488, 0.1972, 0.2114, 1.3974, 1.3972, 1.3972, 1.3967, 1.3967, 1.3966, 1.3965, 1.3964, 1.3962, 1.3961, 1.396, 1.396, 1.3956, 1.3956, 1.3955, 1.3954, 1.3953, 1.3953, 1.3953, 1.3952, 1.3952, 1.3951, 1.3951, 1.395, 1.395, 1.395, 1.395, 1.3949, 1.3948, 1.3948, 1.3708, 1.3835, 1.3944, 1.3792, 1.392, 1.3545, 1.3532, 1.3313, 1.3705, 1.3491, 1.3891, 1.3771, 1.3241, 1.3756, 1.2932, 1.3013, 1.2725, 1.24, 1.1082, 1.3215, 1.3073, 1.1001, 1.1304, 1.0487, 1.1993, 1.2507, 1.3012, 1.1221, 0.988, 1.0748, 1.1232, 1.0872, 1.1897, 1.0977, 0.798, 0.8721, 1.0696, 0.9681, 0.4607, -0.0915, -0.1343, -0.2418, -0.2483, 0.5401, 0.9037, 0.344, -0.8015, 0.0504, 0.092, -0.9901, 0.7403, -0.4503, -0.7862, 2.0228, 2.0228, 2.0227, 2.0226, 2.0219, 2.0217, 2.0216, 2.0215, 2.0215, 2.0215, 2.0214, 2.0213, 2.0211, 2.0211, 2.021, 2.021, 2.021, 2.0208, 2.0207, 2.0207, 2.0207, 2.0205, 2.0205, 2.0204, 2.0203, 2.0203, 2.0202, 2.0201, 2.0201, 2.0201, 2.019, 2.0177, 2.0178, 2.0121, 2.007, 2.0198, 2.0076, 2.0061, 2.0046, 2.0048, 2.0029, 2.0087, 1.8541, 1.8696, 1.842, 1.8297, 1.8555, 1.7662, 1.9684, 1.7875, 1.8739, 1.7675, 1.7816, 1.7003, 1.7145, 1.6995, 1.814, 1.5989, 1.6836, 1.7172, 1.6885, 1.4924, 1.6558, 1.6292, 1.6335, 1.5623, 1.7152, 1.6585, 1.545, 1.6482, 1.7223, 1.5887, -0.3147, 2.0393, 2.0392, 2.0392, 2.0391, 2.0389, 2.0388, 2.0388, 2.0388, 2.0388, 2.0387, 2.0386, 2.0385, 2.0385, 2.0385, 2.0384, 2.0383, 2.0383, 2.0382, 2.0382, 2.0382, 2.0382, 2.0381, 2.038, 2.038, 2.0379, 2.0379, 2.0379, 2.0378, 2.0378, 2.0376, 2.0364, 2.0368, 2.0266, 2.0272, 2.0118, 2.03, 2.0177, 1.9003, 1.9119, 1.6935, 1.9659, 1.9325, 1.6527, 1.697, 1.7664, 1.8794, 0.9279, 1.3628, 1.294, 1.4888, 1.2968, 0.9318, 1.6238, 1.2085, 0.7647, 1.1658, 0.6485, 0.0381, 0.7388, -0.0324, 0.3498, 0.2299, 0.5595, 0.0774, -0.1795, 0.2964, 0.1358, 0.2268, 0.5407, -0.4303, 0.0141, 0.2309, 0.3635, -0.9751, 0.1173], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -6.3103, -7.5108, -7.7116, -7.7577, -7.2074, -7.9103, -7.9561, -7.9632, -7.1718, -8.0753, -8.1264, -8.2396, -8.2755, -8.2976, -8.3344, -8.4165, -8.4697, -8.4787, -8.5028, -8.512, -8.512, -8.5229, -8.5594, -8.6473, -8.6561, -8.6777, -8.7073, -8.713, -8.7186, -8.7243, -6.8257, -6.9701, -7.5843, -7.3788, -7.2265, -7.9574, -8.1434, -8.3873, -7.6562, -7.089, -7.3399, -6.6721, -7.7851, -8.1566, -8.0099, -6.1298, -7.3986, -7.6947, -7.8105, -7.3477, -6.9909, -7.5073, -6.3961, -6.4577, -5.9546, -4.0775, -5.1448, -7.1305, -6.4149, -4.0562, -3.9079, -5.3404, -4.7898, -5.9124, -5.3097, -4.1123, -5.1141, -4.5426, -4.9759, -5.5784, -4.8722, -4.1679, -4.7652, -5.2678, -5.9759, -5.533, -5.868, -6.2418, -5.3449, -5.022, -5.3126, -5.9327, -4.5499, -5.769, -5.534, -5.588, -5.7264, -5.6354, -5.7849, -5.8546, -5.8639, -4.6936, -6.0704, -6.3566, -7.368, -7.4311, -7.5693, -7.6397, -7.7154, -7.8989, -8.0353, -8.039, -8.1025, -5.7681, -8.3435, -6.7969, -8.4415, -8.4579, -8.4745, -8.4801, -8.5145, -8.5233, -7.148, -8.5776, -8.5996, -8.606, -8.6124, -8.622, -8.6651, -8.6926, -8.6926, -3.8501, -6.3274, -7.4562, -6.8373, -8.1279, -5.044, -5.7025, -4.7274, -6.837, -5.8611, -8.0282, -7.4827, -5.5983, -7.7433, -5.2942, -5.8159, -6.0366, -5.6604, -4.008, -7.0158, -6.8398, -4.6375, -5.1531, -4.4553, -5.831, -6.4039, -6.8273, -5.5519, -4.8128, -5.4573, -5.8387, -5.8289, -6.319, -5.9706, -4.9578, -5.2855, -5.9273, -5.8417, -5.0319, -4.3696, -4.6085, -4.7066, -4.7132, -5.4786, -5.7953, -5.6072, -5.2718, -5.6054, -5.6242, -5.5134, -5.7711, -5.6969, -5.7129, -5.8908, -5.9244, -6.0982, -6.4282, -6.4151, -7.3907, -7.477, -7.541, -7.5552, -7.5716, -7.6116, -7.6399, -7.7671, -7.8029, -7.7951, -7.8133, -7.8186, -7.9245, -7.1101, -7.9543, -7.9513, -8.063, -8.063, -8.0698, -7.6255, -8.1079, -8.1474, -8.1773, -7.5606, -8.2002, -5.0253, -5.6835, -6.477, -6.1872, -6.0727, -7.4366, -6.2598, -6.8172, -7.1999, -7.2469, -7.2055, -7.4631, -4.0723, -4.4621, -4.3699, -4.5288, -4.981, -3.8539, -6.9017, -4.7109, -5.999, -5.0601, -5.3345, -4.6495, -4.8223, -4.7032, -5.6495, -4.6431, -5.1765, -5.3982, -5.2452, -4.3894, -5.134, -5.1045, -5.1686, -4.9556, -5.4747, -5.4071, -5.2694, -5.4476, -5.6108, -5.4871, -5.5613, -5.3515, -5.5297, -5.5916, -6.1073, -6.4142, -6.7045, -6.7001, -6.7081, -6.718, -6.7833, -6.8954, -7.0515, -7.0616, -7.0783, -7.1648, -7.2426, -7.2518, -7.2959, -7.3137, -7.3236, -7.3236, -7.4154, -7.43, -7.4337, -7.5185, -7.5327, -7.5368, -7.5659, -7.5872, -7.7011, -5.0642, -6.3192, -6.838, -6.8954, -6.4257, -7.2488, -6.9117, -5.2619, -6.2015, -4.9591, -6.8797, -6.7, -5.2908, -5.9248, -6.2325, -6.6986, -3.5463, -5.1689, -5.0444, -5.7412, -5.4423, -4.7844, -6.2482, -5.6258, -5.2083, -5.7757, -5.1755, -4.4853, -5.3129, -4.5027, -4.9121, -4.8981, -5.2742, -4.8494, -4.6443, -5.1962, -5.0915, -5.1582, -5.4106, -4.8952, -5.2325, -5.3723, -5.4147, -5.2532, -5.4452]}, \"token.table\": {\"Topic\": [2, 2, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 3, 2, 2, 3, 3, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 2, 3, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 4, 3, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 2, 2, 2, 2, 3, 1, 2, 3, 4, 1, 2, 3, 4, 2, 3, 3, 1, 2, 3, 4, 1, 2, 3, 4, 2, 3, 1, 2, 3, 1, 2, 3, 4, 3, 3, 1, 3, 1, 2, 3, 4, 1, 2, 3, 4, 3, 3, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 4, 3, 3, 1, 2, 3, 4, 1, 3, 3, 3, 3, 1, 2, 3, 4, 3, 3, 3, 3, 2, 3, 3, 1, 3, 3, 3, 2, 1, 1, 1, 2, 3, 4, 1, 1, 2, 3, 4, 1, 2, 3, 4, 2, 2, 1, 2, 3, 4, 1, 2, 3, 4, 4, 4, 2, 1, 2, 4, 2, 1, 2, 3, 1, 2, 3, 4, 2, 4, 1, 1, 4, 1, 2, 4, 4, 4, 2, 1, 2, 3, 4, 1, 4, 1, 2, 3, 4, 4, 4, 1, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 4, 1, 2, 3, 4, 2, 1, 2, 3, 4, 1, 2, 4, 2, 4, 1, 2, 4, 1, 2, 3, 4, 1, 3, 4, 1, 1, 4, 1, 2, 3, 4, 1, 1, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 4, 4, 1, 2, 3, 4, 3, 4, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 4, 1, 2, 3, 4, 3, 1, 4, 1, 2, 4, 1, 1, 1, 1, 4, 2, 4, 3, 4, 2, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 3, 4, 1, 1, 2, 3, 4, 1, 2, 3, 4, 2, 3, 1, 3, 4, 1, 4, 1, 2, 3, 4, 1, 2, 3, 4, 2, 1, 2, 3, 1, 2, 3, 2, 2, 3, 1, 2, 2, 3, 4, 1, 2, 3, 4, 3, 1, 2, 3, 4, 1, 4, 1, 2, 3, 4, 2, 1, 1, 2, 3, 2, 3, 1, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 4, 4, 4, 1, 2, 3, 4, 4, 1, 2, 3, 4, 1, 2, 3, 4, 3, 1, 4, 1, 2, 3, 4, 1, 2, 3, 4, 4, 2, 2, 3, 4, 1, 2, 3, 4, 2, 1, 2, 3, 4, 1, 2, 3, 4, 1, 1, 4, 1, 1, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 1, 2, 1, 4, 1, 3, 1, 2, 3, 4, 1, 3, 4, 4, 1, 4, 1, 1, 3, 1, 2, 3, 2, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 1, 2, 3, 4, 4, 1, 2, 1, 2, 3, 4, 1, 3, 4, 1, 2, 1, 2, 3, 4, 1, 2, 3, 4, 4, 4, 4, 1, 2, 3, 4, 2, 3, 4, 1, 2, 3, 4, 1, 1, 2, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 4, 1, 2, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 1, 3, 4, 4, 1, 2, 3, 4, 1, 2, 1, 2, 3, 4, 2, 4, 1, 2, 3, 4, 4, 1, 2, 3, 4, 2, 1, 2, 4, 4, 1, 4, 1, 2, 3, 4, 1, 1, 2, 3, 4, 1, 2, 3, 4, 1, 1, 3, 4, 1, 2, 1, 2, 3, 4, 1, 1, 2, 3, 4, 1, 2, 4, 1, 2, 3, 4, 4, 4], \"Freq\": [0.9998189394145953, 0.9988497652350077, 0.1987939910280983, 0.184692782465285, 0.58817462903797, 0.02831258281752356, 0.052511970757804075, 0.26974570241903567, 0.6543070521791948, 0.023373749389939857, 0.039769523593887184, 0.17955643115150557, 0.7734705958670404, 0.007207696173732219, 0.9974343850548814, 0.999045238056022, 0.017617286612030075, 0.9817633357431305, 0.998079882836256, 0.031344276242268376, 0.23396925727586723, 0.7236076553799413, 0.01112814541145623, 0.05813617423777854, 0.21213986726402698, 0.724107598335296, 0.005540966682269361, 0.09583071142359284, 0.2537797015875602, 0.6307554534742886, 0.01966558573187736, 0.021541626316147502, 0.1272338303004541, 0.8445584670419006, 0.0066813600338853215, 0.010622976907122801, 0.9890550604579073, 0.018663848658834203, 0.24231189878088724, 0.7344648625629869, 0.004559917570056084, 0.0222596252876996, 0.29200204104112765, 0.6773285980400021, 0.008433771071737114, 0.017582288573278343, 0.26358780952773114, 0.7120826872177729, 0.006739877286423365, 0.16347719806107333, 0.11690599961593881, 0.6925587897808712, 0.026904768603200874, 0.018776760528211804, 0.18776760528211806, 0.790052608746825, 0.003367571181690161, 0.025821182787936756, 0.29023009453640913, 0.6744492944209081, 0.009424731717596915, 0.0240190113859666, 0.22959905372097208, 0.736456931787039, 0.010023681916978187, 0.01417580730138011, 0.14344384469288413, 0.834380355160692, 0.008045728468350872, 0.009921239535600167, 0.005952743721360101, 0.9841869619315367, 0.08132092548099296, 0.29029190954832945, 0.619914593726881, 0.008537997339656747, 0.9965820584134278, 0.013021851537216318, 0.13894744882018728, 0.8457048635708619, 0.002289556314235836, 0.017521921690793436, 0.2402133217842495, 0.7349019946359525, 0.007334757917076321, 0.013758342193213969, 0.20651697147752102, 0.7744386430407038, 0.005248027434524916, 0.03468170975518789, 0.27244615845118186, 0.6873284296937237, 0.005378446967382079, 0.9988873804557311, 0.9984557423638714, 0.9966108544315324, 0.978883900257566, 0.0210361869682858, 0.08089559901863441, 0.2565026746411082, 0.647710155737965, 0.014906604762984318, 0.019954179789316677, 0.11687448162314053, 0.857770585748548, 0.005442049033450002, 0.01680406809183663, 0.9822741620955412, 0.9978509505176961, 0.01025124630012168, 0.2693712104708897, 0.7156947032300336, 0.004731344446210006, 0.012595650520957328, 0.28610120469031647, 0.6945601572985041, 0.006837638854233978, 0.0050963263833891555, 0.9948029100375633, 0.004601211310859443, 0.015337371036198142, 0.9800580092130613, 0.09509835823773156, 0.06482761322121419, 0.8114166960622223, 0.028931331520211292, 0.9990640236286087, 0.9984411254990463, 0.0045078512228661225, 0.9947325031791244, 0.013615562329276729, 0.7242634783216815, 0.258906778245859, 0.0031664098440178437, 0.0021294292544649447, 0.17345975801995697, 0.8241778476968696, 0.00017745243787207872, 0.9970438985686659, 0.9970438985686659, 0.0035271403762099558, 0.25183782286139084, 0.740229193620596, 0.004467711143199277, 0.011975243555308462, 0.0019958739258847434, 0.9859617193870633, 0.0019375718928195667, 0.0007045715973889333, 0.9959119529092573, 0.0014091431947778666, 0.009761697156495098, 0.7333668673284334, 0.25055022701670754, 0.0063528505304174445, 0.9987138442805237, 0.9995259636460099, 0.0096528221250053, 0.19646332089716667, 0.7854747415445489, 0.008327924970592806, 0.002375333206369108, 0.9976399466750252, 0.9987694361986147, 0.995651016779392, 0.9997475023446761, 0.08794325202003507, 0.03630684716423466, 0.8612790966182333, 0.014522738865693864, 0.996630818706561, 0.9993270753466279, 0.9981137304276935, 0.9989427159506667, 0.9984161857655046, 0.9998119672695774, 0.9968741047509634, 0.9995401862320451, 0.9963924088631642, 0.9986605972847384, 0.9969743133997405, 0.9964988448332263, 0.9995147360258844, 0.9990379440571112, 0.08881210720915944, 0.0103470416166011, 0.002586760404150275, 0.8984681137081955, 0.9979747419952606, 0.7858152701115637, 0.05952013993682694, 0.009563068508678472, 0.14508968003010617, 0.5243100481444505, 0.04926829794628058, 0.009059009622380623, 0.41735016260300906, 0.9988524489297423, 0.9960699354867608, 0.4701445304965622, 0.4242860152284574, 0.006379765898179871, 0.09923378441624334, 0.5149736746997399, 0.25690939490117504, 0.000524947680631743, 0.22766980908998696, 0.9991665054787422, 0.9985072348190224, 0.9980882825908287, 0.06205240529253298, 0.4620178042596755, 0.4757783794919108, 0.9991366706182127, 0.990611863963606, 0.006560343469957655, 0.0026241373879830623, 0.7687197194755443, 0.10422163675654256, 0.008344542812206838, 0.11869686408384013, 0.9983158183626734, 0.9978872302592253, 0.9998565137757891, 0.011523585030571845, 0.9875712371200072, 0.9944024516929924, 0.0010867786357300463, 0.003260335907190139, 0.9997211038323819, 0.9989644122497312, 0.9973397265399078, 0.0774902380538979, 0.9082841105877422, 0.009094208866961122, 0.005115492487665632, 0.9955195556257633, 0.0035649760273080157, 0.06882216496816401, 0.9010461079624456, 0.027328088196434657, 0.002788580428207618, 0.9974452402916789, 0.9994677708542731, 0.9782072141324546, 0.00955424025824336, 0.012126535712385802, 0.8915384957509217, 0.016908860090951282, 0.016047262124533383, 0.07538982206156622, 0.984861347442385, 0.002283295241365653, 0.009133180965462612, 0.003805492068942755, 0.9991104415502591, 0.3879301150497884, 0.1436355155465908, 0.032839133773077414, 0.4356182484419965, 0.33131555610244334, 0.6509277872626642, 0.015465107959365523, 0.0023685300478307556, 0.3109857826170319, 0.5491297985373824, 0.11717812202606152, 0.02267807003156682, 0.9991474901024612, 0.1391060436883446, 0.8543124459412479, 0.003965742473571228, 0.002745514020164696, 0.9999493056311637, 0.767951154879827, 0.07028678348634297, 0.015490310483607477, 0.14629737678962618, 0.9912462442530319, 0.005610827797658671, 0.0028054138988293357, 0.9947908881900981, 0.004188593213431992, 0.6209806773764253, 0.13018550034750243, 0.24882899547250265, 0.23810206487244465, 0.7056232272920347, 0.016875158236559815, 0.03937536921863957, 0.9423185724058469, 0.04796453187657013, 0.009592906375314025, 0.9994223452626001, 0.4233260864909608, 0.5766651448742096, 0.35597980395070844, 0.5914127262781494, 0.01204743067396893, 0.04049678503659435, 0.9996395491788973, 0.9997475000126995, 0.9529478620941491, 0.025308114825789454, 0.002595704084696354, 0.01914331762463561, 0.7908446616957809, 0.0849862920031287, 0.017443174130271785, 0.10675747174467093, 0.18394403014601396, 0.10128866075572716, 0.035514734824728236, 0.6792392108854974, 0.10324365394763503, 0.1653781326152087, 0.02165292438415446, 0.7098393472022809, 0.9995607301242894, 0.9994001406250692, 0.8389199076978369, 0.1406781732885313, 0.016904697618925723, 0.003497523645294977, 0.9969697342117413, 0.9992574316518751, 0.9993312361045468, 0.6260590974782899, 0.16606184040353783, 0.02070807040917323, 0.18711752830159406, 0.9874367313334449, 0.000744112080884284, 0.001488224161768568, 0.009673457051495691, 0.22468066599256678, 0.7601831053004823, 0.007948991071217165, 0.007300093840913722, 0.7595604310870951, 0.0826971956062038, 0.00873057966766776, 0.14902097622910937, 0.027425494601314274, 0.9579531346600481, 0.011635058315709086, 0.003047277177923808, 0.17034547967183, 0.7488797140159323, 0.03870556688483235, 0.04206124475505938, 0.011961321920719597, 0.9873527549103086, 0.6977527069862126, 0.19288233279027034, 0.02476137965608373, 0.08460805831784812, 0.9972612958603759, 0.9978648871245034, 0.9985053384166754, 0.025365223402963932, 0.973460907042638, 0.0011273432623539526, 0.9996102859497005, 0.9991137703818307, 0.9996863741484223, 0.9990157298994671, 0.9995472067102298, 0.9979581992443692, 0.9976466541922653, 0.9991756765105799, 0.0007091381664376011, 0.9982402996336202, 0.5351603949066308, 0.1588946007881325, 0.026432143997418167, 0.27952897487680584, 0.7419739476812611, 0.1109261592521291, 0.02114861406876932, 0.1259517460095595, 0.4251695660023619, 0.3919129525963304, 0.007950234181239845, 0.17497980207348543, 0.9829755441718528, 0.009013771881884751, 0.0009488180928299739, 0.0071161356962248035, 0.724147181052691, 0.08472486456988229, 0.0065492112871437524, 0.18459292808877117, 0.9778858907967504, 0.0010014192430074249, 0.02052909448165221, 0.9993111482180906, 0.7382475481578974, 0.0908230822366035, 0.007708232071741257, 0.16321343560599966, 0.605850879711812, 0.2771246411391408, 0.027338152008178625, 0.08970122248160321, 0.0022254667218501293, 0.9970090913888578, 0.013167244689102582, 0.984550796071534, 0.0017955333666958065, 0.9976570363379554, 0.0021501229231421456, 0.8025632960860597, 0.13261520442548919, 0.02082604278359146, 0.04401272013963031, 0.9511059012332495, 0.0072551256138978434, 0.006570679801265971, 0.03518051476927822, 0.9977010193800908, 0.0089416156142703, 0.9528019242927095, 0.038261797047110115, 0.006493566607208284, 0.9794462965872495, 0.012987133214416567, 0.9984259232334132, 0.992216785289933, 0.007559746935542346, 0.9986929579118087, 0.9985989152195968, 0.9981805237382628, 0.0011909093542313734, 0.0005954546771156867, 0.9215386686823577, 0.05642779977281154, 0.004327285258651191, 0.017828415265642907, 0.9975782399950623, 0.36028785246407785, 0.14548915693275458, 0.019740608860571007, 0.47455727996535674, 0.020885613060877054, 0.9781428783510754, 0.2748551505971662, 0.04473448932006664, 0.020150670864894884, 0.6597329641166585, 0.9997420308936613, 0.9993419710764593, 0.015357413086326847, 0.9817368513703755, 0.002275172309085459, 0.001965282769396126, 0.9963983640838359, 0.9930265034661195, 0.005630904122389604, 0.000993688962774636, 0.6558009785373337, 0.16450261657290183, 0.015841610313660087, 0.1638772898499942, 0.7033200091844277, 0.14987977320234017, 0.04269174330857618, 0.10408317583495845, 0.023600664233685648, 0.9360720279204734, 0.03983844714655572, 0.00046018008255097363, 0.5972839179636702, 0.13030699532795778, 0.27236512249911815, 0.1477768813391504, 0.7427946049112443, 0.04787608546773379, 0.06151409387786513, 0.3975845885924327, 0.27104645526605503, 0.0010735437353399802, 0.3303247397826539, 0.7238146265806574, 0.08138612956560641, 0.00808699384689958, 0.18668911327417115, 0.9994015440997799, 0.0004077525679721664, 0.9982383448857033, 0.9979585892164725, 0.7520705943502094, 0.21367564026459662, 0.019017772004722332, 0.015223360763395522, 0.998289911081207, 0.8156157123996474, 0.051904810721912525, 0.010302052803757976, 0.12213412387774349, 0.05943548587278945, 0.9138205952941378, 0.02016561127826785, 0.005837413791077536, 0.9965028024908067, 0.008227765957815264, 0.9906230213209578, 0.7597012380980778, 0.12299582795962734, 0.019751154854830668, 0.0974988826015732, 0.7949000786396891, 0.07484066633786807, 0.0063756793079442, 0.1239824406960226, 0.9994676488091357, 0.9986458237461204, 0.001419127512072975, 0.9976466409873014, 0.9986174208393844, 0.8900275283435202, 0.026918903039486256, 0.06848986722704731, 0.014481688344027415, 0.9986615485479212, 0.23727318860448368, 0.6640703049938803, 0.032713323370003745, 0.06588382051381189, 0.15237294081594344, 0.022421243543487172, 0.06451827223738146, 0.7609495512820239, 0.9995402956892692, 0.9983691718090343, 0.0014410640470684675, 0.9993600014636749, 0.998908194537205, 0.19066775230059993, 0.7205057177244697, 0.007055546781167574, 0.08164275561065336, 0.98890468122025, 0.005967528248742888, 0.002983764124371444, 0.0021312600888367455, 0.20883500375559402, 0.7657009085276056, 0.024036192785429032, 0.0013993673881927862, 0.025184721596415816, 0.8203271731025648, 0.1544083965463011, 0.9719195584327184, 0.027737430320568447, 0.9970324765154701, 0.002458773061690432, 0.9981644140777299, 0.0013729909409597384, 0.013369047366007195, 0.9737786543146603, 0.012601038262002526, 0.00025600303466822286, 0.0020499215701323924, 0.0009317825318783601, 0.9970073091098454, 0.9992685641109246, 0.1477820552558203, 0.8524003629120243, 0.9983898853095088, 0.9943747900330662, 0.0054882702912010676, 0.040458932411791576, 0.012028331257559657, 0.9469577153678785, 0.9973397265399078, 0.37535517023210047, 0.5183230029038148, 0.00630588415977916, 0.10006714535518405, 0.39661638154948, 0.06953184236262498, 0.025533696284909323, 0.5083526805813765, 0.6599447836734023, 0.19413361253402242, 0.03720293331405877, 0.10872443756032539, 0.9994290474595479, 0.4546554865069711, 0.21615918184657046, 0.00013480460358376704, 0.32904455688761697, 0.9994064003628723, 0.9994085474924492, 0.9992818159016178, 0.8173245043005158, 0.03776112890119898, 0.11696739927932367, 0.02802480995106405, 0.9844991902149232, 0.011518572769204195, 0.00406537862442501, 0.001577085243498529, 0.9975064165128196, 0.27192470976630756, 0.007857719283965106, 0.012739029748246459, 0.7075519046152215, 0.07134415881261545, 0.00039635643784786365, 0.05826439636363596, 0.8700023810760606, 0.9981955322684655, 0.9995773749936133, 0.9988902295400015, 0.044815695790021204, 0.0021340807519057716, 0.024541928646916376, 0.9293921674549636, 0.986330947390063, 0.011664435551743353, 0.0020584298032488273, 0.052212955956034264, 0.8636217497572624, 0.07491424115431003, 0.009404818153571389, 0.9992019780786828, 0.0021445873242895703, 0.9972331057946502, 0.7659293153133755, 0.09185431243876853, 0.007065716341443732, 0.13514067487522843, 0.2500874321983275, 0.7410599451937454, 0.0066762157224661755, 0.002165259153232273, 0.9704195130245465, 0.0023611180365560743, 0.002833341643867289, 0.024083403972871956, 0.7101459209249521, 0.22560600433541167, 0.0151792665720221, 0.04906116232183493, 0.03456749979357064, 0.9568426489251254, 0.008730966442705986, 0.032091149842998816, 0.9267924074658058, 0.04107667179903848, 0.9195827829712061, 0.07678497868197445, 0.00036739224249748544, 0.003490226303726112, 0.7048839832849728, 0.11723873855990041, 0.014126710704210862, 0.16374024131834863, 0.9654103292316978, 0.02461927801704998, 0.010038928900156303, 0.026252008963335682, 0.0007095137557658292, 0.9727433591549519, 0.9979892138309162, 0.6139096294946379, 0.15759231789651285, 0.09653988659290083, 0.13193979059446936, 0.9994100940990055, 0.0004225835493019051, 0.6230004376130824, 0.1579066493796236, 0.019109340346016666, 0.19995917891850667, 0.998344522241629, 0.0016657583797135076, 0.37300860122196666, 0.6103323618790721, 0.0004988413256061072, 0.016212343082198485, 0.9991578303853179, 0.38678202400342576, 0.3487591842143544, 0.041033965300317644, 0.22341370459913953, 0.9983893137042845, 0.1072331524905592, 0.012313854831451775, 0.8804406204488019, 0.9997970130936787, 0.002615669682873378, 0.9972240665954752, 0.16858493811933553, 0.7593620264639334, 0.025178269978861797, 0.0468291494775932, 0.9987643828187964, 0.669244763580655, 0.2600079623182361, 0.015292001163891525, 0.05545547548514685, 0.7201112855378696, 0.11262866056475863, 0.026684133167299798, 0.1405632813070153, 0.9991014680296477, 0.01565293241688676, 0.9830041557804885, 0.0010435288277924506, 0.9984954883585196, 0.998883666024893, 0.09686656411818255, 0.8825875332569003, 0.006656707012860886, 0.014002038889121174, 0.9989734336826833, 0.06406408422853128, 0.90835579589072, 0.0036459234926806425, 0.024479772022284314, 0.06314955662846994, 0.9293119938411873, 0.007640316727888956, 0.042879413321800036, 0.8124667922869171, 0.1266764367415269, 0.0179364866182693, 0.9997248920046655, 0.9998826077052747], \"Term\": [\"0h24v24h0v0z\", \"0h24v24h0z\", \"10\", \"10\", \"10\", \"10\", \"11\", \"11\", \"11\", \"11\", \"12\", \"12\", \"12\", \"12\", \"12h40c6\", \"12s4\", \"12v\", \"12v\", \"12v40c0\", \"13\", \"13\", \"13\", \"13\", \"14\", \"14\", \"14\", \"14\", \"15\", \"15\", \"15\", \"15\", \"16\", \"16\", \"16\", \"16\", \"163\", \"163\", \"17\", \"17\", \"17\", \"17\", \"18\", \"18\", \"18\", \"18\", \"19\", \"19\", \"19\", \"19\", \"20\", \"20\", \"20\", \"20\", \"21\", \"21\", \"21\", \"21\", \"22\", \"22\", \"22\", \"22\", \"23\", \"23\", \"23\", \"23\", \"24\", \"24\", \"24\", \"24\", \"248\", \"248\", \"248\", \"25\", \"25\", \"25\", \"25\", \"256c0\", \"26\", \"26\", \"26\", \"26\", \"27\", \"27\", \"27\", \"27\", \"28\", \"28\", \"28\", \"28\", \"29\", \"29\", \"29\", \"29\", \"2h14c1\", \"2v14c0\", \"2v5c0\", \"2zm0\", \"2zm0\", \"31\", \"31\", \"31\", \"31\", \"32\", \"32\", \"32\", \"32\", \"327\", \"327\", \"32s14\", \"33\", \"33\", \"33\", \"33\", \"35\", \"35\", \"35\", \"35\", \"373\", \"373\", \"384\", \"384\", \"384\", \"40\", \"40\", \"40\", \"40\", \"40c\", \"40c0\", \"448\", \"448\", \"45\", \"45\", \"45\", \"45\", \"48\", \"48\", \"48\", \"48\", \"48h352c26\", \"48v80c0\", \"49\", \"49\", \"49\", \"49\", \"496\", \"496\", \"496\", \"512\", \"512\", \"512\", \"512\", \"55\", \"55\", \"55\", \"55\", \"576\", \"627\", \"64\", \"64\", \"64\", \"64\", \"673\", \"673\", \"686\", \"714\", \"745\", \"80\", \"80\", \"80\", \"80\", \"80v352c0\", \"837\", \"857\", \"971\", \"9959\", \"__webpack_require__\", \"_asynctogenerator2\", \"_dereq_\", \"_fs\", \"_interoprequiredefault\", \"_load_asynctogenerator\", \"activestep\", \"aes\", \"aj\", \"aliases\", \"aliases\", \"aliases\", \"aliases\", \"anaconda\", \"and\", \"and\", \"and\", \"and\", \"any\", \"any\", \"any\", \"any\", \"api_link\", \"appbar\", \"as\", \"as\", \"as\", \"as\", \"assert\", \"assert\", \"assert\", \"assert\", \"assert_json_error\", \"assert_json_success\", \"assertcontains\", \"assertequal\", \"assertequal\", \"assertequal\", \"auc\", \"axis\", \"axis\", \"axis\", \"be\", \"be\", \"be\", \"be\", \"best_answer\", \"blueslip\", \"bokeh\", \"bot\", \"bot\", \"ca\", \"ca\", \"ca\", \"canonical_name\", \"casper\", \"childat\", \"classes\", \"classes\", \"classes\", \"classes\", \"classmethod\", \"classmethod\", \"classname\", \"classname\", \"classname\", \"classname\", \"client_get\", \"client_post\", \"cls\", \"cls\", \"cls\", \"code\", \"code\", \"code\", \"code\", \"collection\", \"collection\", \"collection\", \"collection\", \"columndatasource\", \"com\", \"com\", \"com\", \"com\", \"component\", \"component\", \"component\", \"component\", \"const\", \"const\", \"const\", \"const\", \"cordelia\", \"createelement\", \"createelement\", \"createelement\", \"createelement\", \"createsvgicon\", \"data\", \"data\", \"data\", \"data\", \"datepicker\", \"datepicker\", \"datepicker\", \"dddd\", \"dddd\", \"def\", \"def\", \"def\", \"default\", \"default\", \"default\", \"default\", \"df\", \"df\", \"df\", \"dflt\", \"dict\", \"dict\", \"div\", \"div\", \"div\", \"div\", \"ea\", \"edittype\", \"el\", \"el\", \"el\", \"el\", \"else\", \"else\", \"else\", \"else\", \"email\", \"email\", \"email\", \"email\", \"equal\", \"equal\", \"equal\", \"equal\", \"example_email\", \"example_user\", \"expect\", \"expect\", \"expect\", \"expect\", \"expect_hybrid\", \"expected_message\", \"expected_topic\", \"false\", \"false\", \"false\", \"false\", \"figure\", \"figure\", \"figure\", \"figure\", \"fill\", \"fill\", \"fill\", \"fill\", \"for\", \"for\", \"for\", \"for\", \"fragment\", \"fragment\", \"fragment\", \"fragment\", \"from\", \"from\", \"from\", \"from\", \"full_name\", \"full_name\", \"function\", \"function\", \"function\", \"function\", \"funs\", \"geom_point\", \"get_realm\", \"gettext\", \"gettext\", \"gettext\", \"ggplot\", \"gl\", \"graphene\", \"ha\", \"hamlet\", \"handleclose\", \"iago\", \"iana\", \"iana\", \"iconbutton\", \"id\", \"id\", \"id\", \"id\", \"if\", \"if\", \"if\", \"if\", \"import\", \"import\", \"import\", \"import\", \"imports\", \"imports\", \"imports\", \"imports\", \"in\", \"in\", \"in\", \"in\", \"inc\", \"inc\", \"inc\", \"inst\", \"is\", \"is\", \"is\", \"is\", \"it\", \"it\", \"it\", \"it\", \"iteratee\", \"iteratee\", \"jp\", \"jp\", \"jp\", \"kw\", \"kw\", \"length\", \"length\", \"length\", \"length\", \"license\", \"license\", \"license\", \"license\", \"listitemtext\", \"m0\", \"m0\", \"m0\", \"m12\", \"m12\", \"m12\", \"m19\", \"m20\", \"m20\", \"ma\", \"markdowndocs\", \"material\", \"material\", \"material\", \"math\", \"math\", \"math\", \"math\", \"memberof\", \"message\", \"message\", \"message\", \"message\", \"message_id\", \"message_id\", \"messages\", \"messages\", \"messages\", \"messages\", \"misago\", \"mobx\", \"mount\", \"mount\", \"mount\", \"museum\", \"museum\", \"na\", \"na\", \"na\", \"name\", \"name\", \"name\", \"name\", \"new\", \"new\", \"new\", \"new\", \"nexport\", \"nexport\", \"nexport\", \"nexport\", \"nfrom\", \"nfrom\", \"nfrom\", \"nimport\", \"nimport\", \"nimport\", \"nimport\", \"none\", \"none\", \"none\", \"none\", \"not\", \"not\", \"not\", \"not\", \"np\", \"np\", \"nrun_test\", \"nset_global\", \"null\", \"null\", \"null\", \"null\", \"nzrequire\", \"of\", \"of\", \"of\", \"of\", \"onclick\", \"onclick\", \"onclick\", \"onclick\", \"oncompleted\", \"operand\", \"operand\", \"options\", \"options\", \"options\", \"options\", \"or\", \"or\", \"or\", \"or\", \"othello\", \"other_thread\", \"packrat\", \"packrat\", \"page_params\", \"param\", \"param\", \"param\", \"param\", \"patch_category_acl\", \"path\", \"path\", \"path\", \"path\", \"payload\", \"payload\", \"payload\", \"payload\", \"pgettext_lazy\", \"plot\", \"plot\", \"plots\", \"plotting\", \"post\", \"post\", \"post\", \"post\", \"product\", \"product\", \"product\", \"product\", \"props\", \"props\", \"props\", \"props\", \"proptypes\", \"proptypes\", \"proptypes\", \"pytest\", \"pytest\", \"r2\", \"r2\", \"rdname\", \"rdname\", \"react\", \"react\", \"react\", \"react\", \"realm\", \"realm\", \"realm\", \"realm_id\", \"recipient\", \"recipient\", \"redash\", \"reddit\", \"reddit\", \"reporter\", \"reporter\", \"reporter\", \"reqsource\", \"response\", \"response\", \"response\", \"response\", \"result\", \"result\", \"result\", \"result\", \"return\", \"return\", \"return\", \"return\", \"saleor\", \"self\", \"self\", \"self\", \"self\", \"send_and_test_stream_message\", \"shiny\", \"snackbar\", \"source\", \"source\", \"source\", \"source\", \"sr\", \"sr\", \"sr\", \"storybook\", \"storybook\", \"str\", \"str\", \"str\", \"str\", \"stream\", \"stream\", \"stream\", \"stream\", \"stream_data\", \"stream_id\", \"stream_name\", \"streams\", \"streams\", \"streams\", \"streams\", \"strictequal\", \"strictequal\", \"strictequal\", \"styles\", \"styles\", \"styles\", \"styles\", \"subreddit\", \"testutils\", \"testutils\", \"the\", \"the\", \"the\", \"the\", \"theme\", \"theme\", \"theme\", \"theme\", \"thing\", \"thing\", \"thing\", \"thing\", \"this\", \"this\", \"this\", \"this\", \"thread\", \"thread\", \"thread\", \"threads\", \"threads\", \"threads\", \"tif\", \"tif\", \"tif\", \"tif\", \"to\", \"to\", \"to\", \"to\", \"tobe\", \"tobe\", \"tobe\", \"topic\", \"topic\", \"topic\", \"topic_name\", \"true\", \"true\", \"true\", \"true\", \"tthis\", \"tthis\", \"type\", \"type\", \"type\", \"type\", \"typography\", \"typography\", \"ui\", \"ui\", \"ui\", \"ui\", \"ujson\", \"user\", \"user\", \"user\", \"user\", \"user_acl\", \"user_id\", \"user_id\", \"user_id\", \"user_profile\", \"userprofile\", \"userprofile\", \"utils\", \"utils\", \"utils\", \"utils\", \"valtype\", \"value\", \"value\", \"value\", \"value\", \"var\", \"var\", \"var\", \"var\", \"vec4\", \"vnd\", \"vnd\", \"vnd\", \"voucher\", \"withstyles\", \"wrapper\", \"wrapper\", \"wrapper\", \"wrapper\", \"xa\", \"xa4\", \"xa4\", \"xa4\", \"xa4\", \"xe0\", \"xe0\", \"xe0\", \"xe2\", \"xe2\", \"xe2\", \"xe2\", \"zerver\", \"zulip\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [3, 4, 2, 1]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el100081396561175280408114403987\", ldavis_el100081396561175280408114403987_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el100081396561175280408114403987\", ldavis_el100081396561175280408114403987_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el100081396561175280408114403987\", ldavis_el100081396561175280408114403987_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "2      0.150973 -0.000614       1        1  49.041760\n",
       "3     -0.016625 -0.167877       2        1  24.723611\n",
       "1     -0.302164  0.065904       3        1  13.224716\n",
       "0      0.167816  0.102586       4        1  13.009913, topic_info=       Category          Freq           Term         Total  loglift  logprob\n",
       "term                                                                        \n",
       "224987  Default  74181.000000           self  74181.000000  30.0000  30.0000\n",
       "209790  Default  35155.000000          react  35155.000000  29.0000  29.0000\n",
       "6203    Default  23585.000000             12  23585.000000  28.0000  28.0000\n",
       "10108   Default  17361.000000             16  17361.000000  27.0000  27.0000\n",
       "118970  Default  39038.000000           from  39038.000000  26.0000  26.0000\n",
       "16221   Default  13050.000000             24  13050.000000  25.0000  25.0000\n",
       "88624   Default  14728.000000  createsvgicon  14728.000000  24.0000  24.0000\n",
       "4646    Default  18154.000000             10  18154.000000  23.0000  23.0000\n",
       "20365   Default  11576.000000             32  11576.000000  22.0000  22.0000\n",
       "25767   Default  11270.000000             48  11270.000000  21.0000  21.0000\n",
       "256596  Default  70622.000000            the  70622.000000  20.0000  20.0000\n",
       "178605  Default  15211.000000        nexport  15211.000000  19.0000  19.0000\n",
       "8196    Default  11369.000000             14  11369.000000  18.0000  18.0000\n",
       "93741   Default  26488.000000        default  26488.000000  17.0000  17.0000\n",
       "5507    Default  12663.000000             11  12663.000000  16.0000  16.0000\n",
       "15259   Default   9799.000000             21   9799.000000  15.0000  15.0000\n",
       "7684    Default  10783.000000             13  10783.000000  14.0000  14.0000\n",
       "182715  Default  21424.000000           none  21424.000000  13.0000  13.0000\n",
       "10837   Default   9429.000000             17   9429.000000  12.0000  12.0000\n",
       "118218  Default  10829.000000       fragment  10829.000000  11.0000  11.0000\n",
       "238426  Default   8399.000000            str   8399.000000  10.0000  10.0000\n",
       "180274  Default  20970.000000        nimport  20970.000000   9.0000   9.0000\n",
       "139409  Default  33744.000000             in  33744.000000   8.0000   8.0000\n",
       "17250   Default   6988.000000             26   6988.000000   7.0000   7.0000\n",
       "27860   Default   5677.000000            512   5677.000000   6.0000   6.0000\n",
       "9620    Default   9610.000000             15   9610.000000   5.0000   5.0000\n",
       "138187  Default  74472.000000             if  74472.000000   4.0000   4.0000\n",
       "210709  Default   5366.000000          realm   5366.000000   3.0000   3.0000\n",
       "17808   Default   7050.000000             28   7050.000000   2.0000   2.0000\n",
       "166131  Default  11499.000000        message  11499.000000   1.0000   1.0000\n",
       "...         ...           ...            ...           ...      ...      ...\n",
       "211325   Topic4   1043.602861      recipient   1224.776579   1.8794  -6.6986\n",
       "224987   Topic4  24409.028588           self  74181.442875   0.9279  -3.5463\n",
       "216694   Topic4   4817.857855         result   9477.672065   1.3628  -5.1689\n",
       "166131   Topic4   5456.608823        message  11499.138735   1.2940  -5.0444\n",
       "96945    Topic4   2718.527332           dict   4715.041344   1.4888  -5.7412\n",
       "59130    Topic4   3665.434449    assertequal   7703.166344   1.2968  -5.4423\n",
       "182715   Topic4   7077.002441           none  21424.371679   0.9318  -4.7844\n",
       "166471   Topic4   1637.375695       messages   2481.306967   1.6238  -6.2482\n",
       "83034    Topic4   3051.074424            com   7003.838822   1.2085  -5.6258\n",
       "137816   Topic4   4631.711734             id  16570.732970   0.7647  -5.2083\n",
       "56394    Topic4   2626.381485            any   6292.078536   1.1658  -5.7757\n",
       "93727    Topic4   4786.163104            def  19234.092839   0.6485  -5.1755\n",
       "256596   Topic4   9544.348309            the  70622.704887   0.0381  -4.4853\n",
       "179191   Topic4   4171.843620          nfrom  15317.673429   0.7388  -5.3129\n",
       "138187   Topic4   9379.984936             if  74472.965220  -0.0324  -4.5027\n",
       "139409   Topic4   6228.756762             in  33744.521334   0.3498  -4.9121\n",
       "259512   Topic4   6316.713182             to  38579.398376   0.2299  -4.8981\n",
       "59010    Topic4   4336.589341         assert  19049.517445   0.5595  -5.2742\n",
       "273107   Topic4   6632.025491            var  47181.596348   0.0774  -4.8494\n",
       "216978   Topic4   8141.649666         return  74886.568123  -0.1795  -4.6443\n",
       "139197   Topic4   4688.213274         import  26791.663635   0.2964  -5.1962\n",
       "116995   Topic4   5205.970258            for  34934.679209   0.1358  -5.0915\n",
       "143466   Topic4   4869.969296             is  29838.229812   0.2268  -5.1582\n",
       "270897   Topic4   3783.745950           user  16937.188373   0.5407  -5.4106\n",
       "119762   Topic4   6334.812398       function  74874.664730  -0.4303  -4.8952\n",
       "263540   Topic4   4521.120575           true  34265.629645   0.0141  -5.2325\n",
       "173909   Topic4   3931.270273           name  23987.460396   0.2309  -5.3723\n",
       "111706   Topic4   3768.163633          false  20137.076597   0.3635  -5.4147\n",
       "257199   Topic4   4428.481626           this  90254.690073  -0.9751  -5.2532\n",
       "92062    Topic4   3654.778962           data  24983.359785   0.1173  -5.4452\n",
       "\n",
       "[352 rows x 6 columns], token_table=        Topic      Freq          Term\n",
       "term                                 \n",
       "2713        2  0.999819  0h24v24h0v0z\n",
       "2718        2  0.998850    0h24v24h0z\n",
       "4646        1  0.198794            10\n",
       "4646        2  0.184693            10\n",
       "4646        3  0.588175            10\n",
       "4646        4  0.028313            10\n",
       "5507        1  0.052512            11\n",
       "5507        2  0.269746            11\n",
       "5507        3  0.654307            11\n",
       "5507        4  0.023374            11\n",
       "6203        1  0.039770            12\n",
       "6203        2  0.179556            12\n",
       "6203        3  0.773471            12\n",
       "6203        4  0.007208            12\n",
       "7291        3  0.997434       12h40c6\n",
       "7439        2  0.999045          12s4\n",
       "7448        2  0.017617           12v\n",
       "7448        3  0.981763           12v\n",
       "7544        3  0.998080       12v40c0\n",
       "7684        1  0.031344            13\n",
       "7684        2  0.233969            13\n",
       "7684        3  0.723608            13\n",
       "7684        4  0.011128            13\n",
       "8196        1  0.058136            14\n",
       "8196        2  0.212140            14\n",
       "8196        3  0.724108            14\n",
       "8196        4  0.005541            14\n",
       "9620        1  0.095831            15\n",
       "9620        2  0.253780            15\n",
       "9620        3  0.630755            15\n",
       "...       ...       ...           ...\n",
       "272814      3  0.015292         value\n",
       "272814      4  0.055455         value\n",
       "273107      1  0.720111           var\n",
       "273107      2  0.112629           var\n",
       "273107      3  0.026684           var\n",
       "273107      4  0.140563           var\n",
       "273470      1  0.999101          vec4\n",
       "275366      1  0.015653           vnd\n",
       "275366      3  0.983004           vnd\n",
       "275366      4  0.001044           vnd\n",
       "275660      1  0.998495       voucher\n",
       "279284      2  0.998884    withstyles\n",
       "280154      1  0.096867       wrapper\n",
       "280154      2  0.882588       wrapper\n",
       "280154      3  0.006657       wrapper\n",
       "280154      4  0.014002       wrapper\n",
       "281187      1  0.998973            xa\n",
       "281311      1  0.064064           xa4\n",
       "281311      2  0.908356           xa4\n",
       "281311      3  0.003646           xa4\n",
       "281311      4  0.024480           xa4\n",
       "281885      1  0.063150           xe0\n",
       "281885      2  0.929312           xe0\n",
       "281885      4  0.007640           xe0\n",
       "281915      1  0.042879           xe2\n",
       "281915      2  0.812467           xe2\n",
       "281915      3  0.126676           xe2\n",
       "281915      4  0.017936           xe2\n",
       "284097      4  0.999725        zerver\n",
       "284640      4  0.999883         zulip\n",
       "\n",
       "[732 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[3, 4, 2, 1])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyLDAvis.sklearn.prepare(model, tf, tf_vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying Program Subjects and Themes\n",
    "\n",
    "Hypothesis: Using tf-idf rather than bag-of-words as an input to LDA will prioritise rare words. In the case of source code, this means programming language keywords (an identifying feature of programming languages) are deprioritised, and so a more human idea of topics may emerge. \n",
    "\n",
    "We can use repo-list.json and the repo-ids to map the github topics/tags to each repo. Might be a small/easy task to compare against the programming langauge identification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = minimal_dataset['documents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_vectorizer = TfidfVectorizer(stop_words=None)\n",
    "tf = tf_vectorizer.fit_transform(documents)\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "\n",
    "with open('../data/tfidf_lda_tf.pickle', 'wb') as f:\n",
    "    pickle.dump(tf, model)\n",
    "    \n",
    "with open('../data/tfidf_lda_tf_vectorizer.pickle', 'wb') as f:\n",
    "    pickle.dump(tf_vectorizer, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have four programming languages, try to use LDA to determine these four programming languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "number_of_themes = 3\n",
    "\n",
    "lda = LatentDirichletAllocation(n_topics=number_of_themes,  n_jobs=1)\n",
    "model = lda.fit(tf)\n",
    "\n",
    "with open('../data/tfidf_lda_model.pickle', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/tfidf_lda_model.pickle', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "    \n",
    "with open('../data/tfidf_lda_tf.pickle', 'wb') as f:\n",
    "    tf = pickle.load(model)\n",
    "    \n",
    "with open('../data/tfidf_lda_tf_vectorizer.pickle', 'wb') as f:\n",
    "    tf_vectorizer = pickle.load(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pyLDAvis.sklearn.prepare(model, tf, tf_vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This still prioritises programming language keywords. One approach to solving this problem is to consider all keywords as \"stopwords\". First, gather a list of R, Python and Javascript keywords:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keyword\n",
    "\n",
    "python_keywords = keyword.kwlist\n",
    "python_keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R reserved words (sourced from the manual: https://stat.ethz.ch/R-manual/R-devel/library/base/html/Reserved.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_keywords = [\n",
    "    \"if\", \n",
    "    \"else\", \n",
    "    \"repeat\",\n",
    "    \"while\",\n",
    "    \"function\", \n",
    "    \"for\",\n",
    "    \"in\",\n",
    "    \"next\",\n",
    "    \"break\",\n",
    "    \"TRUE\",\n",
    "    \"FALSE\",\n",
    "    \"NULL\", \n",
    "    \"Inf\", \n",
    "    \"NaN\",\n",
    "    \"NA\",\n",
    "    \"NA_integer_\",\n",
    "    \"NA_real_\",\n",
    "    \"NA_complex_\",\n",
    "    \"NA_character_\", \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Javascript keywords and reserved words (source: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Lexical_grammar#Keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "javascript_keywords = [  # jaccard(\"ideal javascript topic\", topic_i)\n",
    "    \"break\",\n",
    "    \"case\",\n",
    "    \"catch\",\n",
    "    \"class\",\n",
    "    \"const\",\n",
    "    \"continue\",\n",
    "    \"debugger\",\n",
    "    \"default\",\n",
    "    \"delete\",\n",
    "    \"do\",\n",
    "    \"else\",\n",
    "    \"export\",\n",
    "    \"extends\",\n",
    "    \"finally\",\n",
    "    \"for\",\n",
    "    \"function\",\n",
    "    \"if\",\n",
    "    \"import\",\n",
    "    \"in\",\n",
    "    \"instanceof\",\n",
    "    \"new\",\n",
    "    \"return\",\n",
    "    \"super\",\n",
    "    \"switch\",\n",
    "    \"this\",\n",
    "    \"throw\",\n",
    "    \"try\",\n",
    "    \"typeof\",\n",
    "    \"var\",\n",
    "    \"void\",\n",
    "    \"while\",\n",
    "    \"with\",\n",
    "    \"yield\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = minimal_dataset['documents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_vectorizer = TfidfVectorizer(stop_words=javascript_keywords+python_keywords+r_keywords)\n",
    "tf = tf_vectorizer.fit_transform(documents)\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "    \n",
    "with open('../data/tfidf_lda_tf_ignore_keywords.pickle', 'rb') as f:\n",
    "    pickle.dump(tf, f)\n",
    "    \n",
    "with open('../data/tfidf_lda_tf_vectoriser_ignore_keywords.pickle', 'rb') as f:\n",
    "    pickle.dump(tf_vectoriser, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have four programming languages, try to use LDA to determine these four programming languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "number_of_themes = 3\n",
    "\n",
    "lda = LatentDirichletAllocation(n_topics=number_of_themes,  n_jobs=1)\n",
    "model = lda.fit(tf)\n",
    "\n",
    "with open('../data/tfidf_lda_model_ignore_keywords.pickle', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/tfidf_lda_model_ignore_keywords.pickle', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "    \n",
    "with open('../data/tfidf_lda_tf_ignore_keywords.pickle', 'rb') as f:\n",
    "    tf = pickle.load(f)\n",
    "    \n",
    "with open('../data/tfidf_lda_tf_vectoriser_ignore_keywords.pickle', 'rb') as f:\n",
    "    tf_vectoriser = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pyLDAvis.sklearn.prepare(model, tf, tf_vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring the Efficacy of Topic Models (WRITEUP: WHO?)\n",
    "\n",
    "Main question: How do we evaluate how well a topic (from LDA for example) represents a meaningful \"topic\" or theme?\n",
    "\n",
    "TODO: do some research on this??? There must be some papers etc that try to formalise this that we can borrow ideas from?\n",
    "\n",
    "Paper dump:\n",
    "  - Looks like a good summary paper: http://www.aclweb.org/anthology/E14-4005 Find more papers from this ones references?\n",
    "    - \" KL-divergence (Li and McCallum, 2006; Wang et al., 2009; Newman et al., 2009), cosine measure (He et al., 2009; Ramage et al., 2009) and the average Log Odds Ratio (Chaney and Blei, 2012). \"\n",
    "    - \"Kim and Oh (2011) also applied  the  cosine  measure  and  KL-Divergence which were compared with four other measures: Jaccard’s Coefficient, Kendall’s τ coefficient, Discount  Cumulative  Gain  and  Jensen  Shannon  Divergence (JSD).\"\n",
    "  - Cool name haven't read it: http://papers.nips.cc/paper/3700-reading-tea-leaves-how-humans-interpret-topic-models.pdf\n",
    "  \n",
    "We considered all of these metrics, and found th Jaccard Index to be most suitable. This was primarily due to it's use of set operations, which are invariant to ordering and number of observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Tea Leaves Paper\n",
    "http://papers.nips.cc/paper/3700-reading-tea-leaves-how-humans-interpret-topic-models.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Overlap\n",
    "\n",
    "I think this is used as a baseline measure in the summary paper above (http://www.aclweb.org/anthology/E14-4005). Should be a quick implementation so worth a try."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jaccard Index\n",
    "\n",
    "From the papers above this seems to have been used relatively often for _linking machine-generated topics to human topics_ and so maybe this is a good application for it. Apparently explored here \"https://link.springer.com/chapter/10.1007/978-3-642-19437-5_13\" but I haven't read it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_index(a, b):\n",
    "    a = set(a)\n",
    "    b = set(b)\n",
    "    return len(a & b) / len(a | b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the group of language keywords as the best possible topic for each language. Compare each of our machine generated topics with each of our ideal topics by computing their Jaccard Index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_vectorizer = CountVectorizer(stop_words=None)\n",
    "tf = tf_vectorizer.fit_transform(documents)\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tf_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(enumerate(model.components_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kendall’s τ Coefficient\n",
    "\n",
    "Measures the association between two ranked lists. Source: Computational Linguistics and Intelligent Text Processing book."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Topic Models\n",
    "TODO: better title needed\n",
    "\n",
    "Idea:\n",
    "  - save the actual % of each program langauge per repo\n",
    "  - Then try to use LDA model to tell us \"I believe repo <x> is 10% Topic 1, 20% Topic 2 etc\". \n",
    "  - Use analysis from above two sections to create a \"most likely mapping from lda topic to programming language\".\n",
    "  - rate our models\n",
    "\n",
    "Here we can do cross-validation etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in the test data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>language</th>\n",
       "      <th>documents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69798748</td>\n",
       "      <td>javascript</td>\n",
       "      <td>b\"const glob = require('glob')\\nconst markdown...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>128624453</td>\n",
       "      <td>javascript</td>\n",
       "      <td>b\"module.exports = {\\n  extends: ['@commitlint...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>128624453</td>\n",
       "      <td>javascript</td>\n",
       "      <td>b\"module.exports = {\\n  extends: ['standard', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>128624453</td>\n",
       "      <td>javascript</td>\n",
       "      <td>b\"const cp = require('child_process')\\nconst g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>128624453</td>\n",
       "      <td>javascript</td>\n",
       "      <td>b\"module.exports = {\\n  verbose: true,\\n  tran...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        repo    language                                          documents\n",
       "0   69798748  javascript  b\"const glob = require('glob')\\nconst markdown...\n",
       "1  128624453  javascript  b\"module.exports = {\\n  extends: ['@commitlint...\n",
       "2  128624453  javascript  b\"module.exports = {\\n  extends: ['standard', ...\n",
       "3  128624453  javascript  b\"const cp = require('child_process')\\nconst g...\n",
       "4  128624453  javascript  b\"module.exports = {\\n  verbose: true,\\n  tran..."
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = pandas.read_csv(\"../data/test-dataset.csv.gz\", header=None, names=['repo', 'language', 'topics', 'documents'])\n",
    "\n",
    "# Remove Github 'topics' since we don't use them in this analysis\n",
    "test_dataset = test_dataset.drop(columns='topics')\n",
    "\n",
    "test_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the mixture model, we must label each repository with it's percentage of each programming language:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_language_percentages(group):\n",
    "    total_python_length = 0\n",
    "    total_r_length = 0\n",
    "    total_javascript_length = 0\n",
    "    \n",
    "    for index, repo, language, document in group.itertuples():\n",
    "        if language == 'python':\n",
    "            total_python_length += len(document)\n",
    "            \n",
    "        if language == 'javascript':\n",
    "            total_javascript_length += len(document)\n",
    "            \n",
    "        if language == 'r':\n",
    "            total_r_length += len(document)\n",
    "            \n",
    "    total_length = total_python_length + total_r_length + total_javascript_length\n",
    "            \n",
    "    return pandas.Series([\n",
    "        total_python_length/total_length,\n",
    "        total_r_length/total_length,\n",
    "        total_javascript_length/total_length,\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_test_documents = test_dataset.groupby(by='repo').apply(calculate_language_percentages)\n",
    "combined_test_documents.columns = ['python', 'r', 'javascript']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the programming language percentages for each of repository in our test dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>python</th>\n",
       "      <th>r</th>\n",
       "      <th>javascript</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>repo</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>596892</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1248263</th>\n",
       "      <td>0.652443</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.347557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1790564</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4751958</th>\n",
       "      <td>0.360730</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.639270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12465340</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.995105</td>\n",
       "      <td>0.004895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13523710</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14267375</th>\n",
       "      <td>0.941701</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14579179</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.189083</td>\n",
       "      <td>0.810917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16146440</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.253421</td>\n",
       "      <td>0.746579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17856544</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19117456</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21289110</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23932217</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.984244</td>\n",
       "      <td>0.015756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24929423</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28556914</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.127105</td>\n",
       "      <td>0.872895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33614304</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36849200</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.980459</td>\n",
       "      <td>0.019541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38226908</th>\n",
       "      <td>0.659855</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.340145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45936895</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47918643</th>\n",
       "      <td>0.555986</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.444014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61412022</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69798748</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72671522</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83222441</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84232645</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89187780</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94911145</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128624453</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             python         r  javascript\n",
       "repo                                     \n",
       "596892     1.000000  0.000000    0.000000\n",
       "1248263    0.652443  0.000000    0.347557\n",
       "1790564    0.000000  0.000000    1.000000\n",
       "4751958    0.360730  0.000000    0.639270\n",
       "12465340   0.000000  0.995105    0.004895\n",
       "13523710   0.000000  1.000000    0.000000\n",
       "14267375   0.941701  0.000000    0.058299\n",
       "14579179   0.000000  0.189083    0.810917\n",
       "16146440   0.000000  0.253421    0.746579\n",
       "17856544   0.000000  1.000000    0.000000\n",
       "19117456   0.000000  0.000000    1.000000\n",
       "21289110   1.000000  0.000000    0.000000\n",
       "23932217   0.000000  0.984244    0.015756\n",
       "24929423   0.000000  1.000000    0.000000\n",
       "28556914   0.000000  0.127105    0.872895\n",
       "33614304   1.000000  0.000000    0.000000\n",
       "36849200   0.000000  0.980459    0.019541\n",
       "38226908   0.659855  0.000000    0.340145\n",
       "45936895   0.000000  0.000000    1.000000\n",
       "47918643   0.555986  0.000000    0.444014\n",
       "61412022   0.000000  0.000000    1.000000\n",
       "69798748   0.000000  0.000000    1.000000\n",
       "72671522   0.000000  1.000000    0.000000\n",
       "83222441   1.000000  0.000000    0.000000\n",
       "84232645   0.000000  0.000000    1.000000\n",
       "89187780   0.000000  0.000000    1.000000\n",
       "94911145   0.000000  0.000000    1.000000\n",
       "128624453  0.000000  0.000000    1.000000"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_test_documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes:\n",
    "  - our keyword lists have simliar/common words e.g. python javascript and r all share some keywords. this can be seen in the documents. choosing another language, with a completely different set of keywords might prove easier to differentiate for the LDA model. somethind somthing LDA uses distance, but if true topics share key words, then distance metric breaks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
