{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modelling on Program Source Code\n",
    "---\n",
    "By Kishalay Banerjee, Dan Jones and Sam Harding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # 0y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import pickle\n",
    "import numpy\n",
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "pyLDAvis.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "from urllib.request import urlretrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.random.seed(0xD00D5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "\n",
    "There are a number of files which are too large to store on GitHub. These are hosted on our server, and can be downloaded by running the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\n",
    "    'full_lda_model.pickle',\n",
    "    'full_tf.pickle',\n",
    "    'full_tf_vectorizer.pickle',\n",
    "    'full-dataset.csv.gz',\n",
    "]\n",
    "\n",
    "base_url = 'https://daniel.wilshirejones.com/private-uUX6IzfsRYLNiti4ZFmgv6U3dFInnq37r5YSQs46iejeB96q0MAy9Ko7hkgo/'\n",
    "destination_directory = '../data/'\n",
    "\n",
    "for file in files:\n",
    "    url = base_url + file\n",
    "    destination = destination_directory + file\n",
    "    print(\"Downloading '{}'' to location '{}'\".format(url, destination))\n",
    "    urlretrieve(url, destination)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating the Dataset\n",
    "\n",
    "TODO: Import dataset.py and explain how it's used + what it does.\n",
    "\n",
    "TODO: Add Sam's scrub function in here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>language</th>\n",
       "      <th>documents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28457823</td>\n",
       "      <td>javascript</td>\n",
       "      <td>b\"module.exports = {\\n  plugins: [\\n    requir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28457823</td>\n",
       "      <td>javascript</td>\n",
       "      <td>b\"// The path where to mount the REST API app\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28457823</td>\n",
       "      <td>javascript</td>\n",
       "      <td>b\"import { Observable } from 'rx';\\nimport deb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28457823</td>\n",
       "      <td>javascript</td>\n",
       "      <td>b\"import { Observable } from 'rx';\\n// import ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28457823</td>\n",
       "      <td>javascript</td>\n",
       "      <td>b\"import { Observable } from 'rx';\\n\\nmodule.e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       repo    language                                          documents\n",
       "0  28457823  javascript  b\"module.exports = {\\n  plugins: [\\n    requir...\n",
       "1  28457823  javascript  b\"// The path where to mount the REST API app\\...\n",
       "2  28457823  javascript  b\"import { Observable } from 'rx';\\nimport deb...\n",
       "3  28457823  javascript  b\"import { Observable } from 'rx';\\n// import ...\n",
       "4  28457823  javascript  b\"import { Observable } from 'rx';\\n\\nmodule.e..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minimal_dataset = pandas.read_csv(\"../data/dataset.csv.gz\", header=None, names=['repo', 'language', 'documents'])\n",
    "minimal_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = pandas.read_csv(\"../data/full-dataset.csv.gz\", header=None, names=['repo', 'language',  'topics', 'documents'])\n",
    "\n",
    "# Remove Github 'topics' since we don't use them in this analysis\n",
    "full_dataset.drop(columns='topics')\n",
    "\n",
    "full_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modelling on Individual Source Files\n",
    "\n",
    "Basically done, just need to copy it over. Maybe run on the bigger dataset?\n",
    "\n",
    "TODO:\n",
    "  - Copy work from documentation/daniel-jones.ipynb\n",
    "  - Add visualisation with pyldavis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our purposes, common words are important and rare words aren't. So we shouldn't use tf-idf as a metric, bag-of-words makes more sense. (TODO: Maybe: \"Similarly, filter out words that don't occur very often\").\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = minimal_dataset['documents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_vectorizer = CountVectorizer(stop_words=None)\n",
    "tf = tf_vectorizer.fit_transform(documents)\n",
    "\n",
    "with open('../data/minimal_lda_tf.pickle', 'wb') as f:\n",
    "    pickle.dump(tf, f)\n",
    "    \n",
    "with open('../data/minimal_lda_tf_vectorizer.pickle', 'wb') as f:\n",
    "    pickle.dump(tf_vectorizer, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have four programming languages, try to use LDA to determine these four programming languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_languages = 4\n",
    "\n",
    "lda = LatentDirichletAllocation(n_topics=number_of_languages,  n_jobs=1)\n",
    "model = lda.fit(tf)\n",
    "\n",
    "with open('../data/minimal_lda_model.pickle', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/minimal_lda_model.pickle', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "    \n",
    "with open('../data/minimal_lda_tf.pickle', 'rb') as f:\n",
    "    tf = pickle.load(f)\n",
    "    \n",
    "with open('../data/minimal_lda_tf_vectorizer.pickle', 'rb') as f:\n",
    "    tf_vectorizer = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.sklearn.prepare(model, tf, tf_vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to do this on the full dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_languages = 4\n",
    "all_documents = full_dataset['documents']\n",
    "\n",
    "full_tf_vectorizer = CountVectorizer(stop_words=None)\n",
    "full_tf = full_tf_vectorizer.fit_transform(all_documents)\n",
    "full_tf_feature_names = full_tf_vectorizer.get_feature_names()\n",
    "\n",
    "full_lda = LatentDirichletAllocation(n_topics=number_of_languages,  n_jobs=1)\n",
    "full_model = full_lda.fit(full_tf)\n",
    "\n",
    "with open('../data/full_lda_model.pickle', 'wb') as f:\n",
    "    pickle.dump(full_model, f)\n",
    "\n",
    "with open('../data/full_tf.pickle', 'wb') as f:\n",
    "    pickle.dump(full_tf, f)\n",
    "    \n",
    "with open('../data/full_tf_vectorizer.pickle', 'wb') as f:\n",
    "    pickle.dump(full_tf_vectorizer, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/full_lda_model.pickle', 'rb') as f:\n",
    "    full_model = pickle.load(f)\n",
    "\n",
    "with open('../data/full_tf.pickle', 'rb') as f:\n",
    "    full_tf = pickle.load(f)\n",
    "    \n",
    "with open('../data/full_tf_vectorizer.pickle', 'rb') as f:\n",
    "    full_tf_vectorizer = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize our new model. Note that the following code cell requires more than 8 GB of RAM to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.sklearn.prepare(full_model, full_tf, full_tf_vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://nbviewer.jupyter.org/github/bmabey/pyLDAvis/blob/master/notebooks/sklearn.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modelling on Programming Language Mixtures\n",
    "Keypoint: topics are programming languages, file with mixture of programming languages, identify which is which.\n",
    "\n",
    "Applicability to cyber-security: identifying malware embedded within normal programs (shellcode)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining Source Files per Repository\n",
    "\n",
    "Currently our data set consists of one data point per file containing:\n",
    "  1. ID of the Github repository the file belongs to.\n",
    "  2. Programming language it is written in (identified by file extension).\n",
    "  3. File contents\n",
    "  \n",
    "In this section, we extend our analysis from working on documents with one language per file, to a system where there is a mixture of languages inside each document. To do this, we combine all the files in each repository into a single data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_texts(group):\n",
    "    [repo_id] = group['repo'].unique()\n",
    "    combined = ' '.join(group['documents'])\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_documents = minimal_dataset.groupby(by='repo').apply(concat_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "repo\n",
       "19438      b\"#' @include ggplot-global.R\\n#' @include ggp...\n",
       "26554      b'# The contents of this file are subject to t...\n",
       "544208     b'import logging\\nimport os\\nimport platform a...\n",
       "643909     b'#\\' Environment variables to set when callin...\n",
       "2594513    b'# S3 method to deal with chunks and inline t...\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_documents.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_vectorizer = CountVectorizer(stop_words=None, token_pattern=\"[^ ]*\")\n",
    "tf = tf_vectorizer.fit_transform(combined_documents)\n",
    "\n",
    "with open('../data/concatDocs_tf_vectorizer.pickle', 'wb') as f:\n",
    "    pickle.dump(tf_vectorizer, f)\n",
    "    \n",
    "with open('../data/concatDocs_tf.pickle', 'wb') as f:\n",
    "    pickle.dump(tf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dan/.guix-profile/lib/python3.7/site-packages/sklearn/decomposition/online_lda.py:314: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "number_of_languages = 4\n",
    "\n",
    "lda = LatentDirichletAllocation(n_topics=number_of_languages,  n_jobs=1)\n",
    "model = lda.fit(tf)\n",
    "\n",
    "with open('../data/concatDocs_lda_model.pickle', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/concatDocs_lda_model.pickle', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "    \n",
    "with open('../data/concatDocs_tf.pickle', 'rb') as f:\n",
    "    tf = pickle.load(f)\n",
    "    \n",
    "with open('../data/concatDocs_tf_vectorizer.pickle', 'rb') as f:\n",
    "    tf_vectorizer = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis = pyLDAvis.sklearn.prepare(model, tf, tf_vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.display(vis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying Program Subjects and Themes\n",
    "\n",
    "Hypothesis: Using tf-idf rather than bag-of-words as an input to LDA will prioritise rare words. In the case of source code, this means programming language keywords (an identifying feature of programming languages) are deprioritised, and so a more human idea of topics may emerge. \n",
    "\n",
    "We can use repo-list.json and the repo-ids to map the github topics/tags to each repo. Might be a small/easy task to compare against the programming langauge identification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = minimal_dataset['documents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_vectorizer = TfidfVectorizer(stop_words=None)\n",
    "tf = tf_vectorizer.fit_transform(documents)\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "\n",
    "with open('../data/tfidf_lda_tf.pickle', 'wb') as f:\n",
    "    pickle.dump(tf, model)\n",
    "    \n",
    "with open('../data/tfidf_lda_tf_vectorizer.pickle', 'wb') as f:\n",
    "    pickle.dump(tf_vectorizer, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have four programming languages, try to use LDA to determine these four programming languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "number_of_themes = 3\n",
    "\n",
    "lda = LatentDirichletAllocation(n_topics=number_of_themes,  n_jobs=1)\n",
    "model = lda.fit(tf)\n",
    "\n",
    "with open('../data/tfidf_lda_model.pickle', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/tfidf_lda_model.pickle', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "    \n",
    "with open('../data/tfidf_lda_tf.pickle', 'wb') as f:\n",
    "    tf = pickle.load(model)\n",
    "    \n",
    "with open('../data/tfidf_lda_tf_vectorizer.pickle', 'wb') as f:\n",
    "    tf_vectorizer = pickle.load(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pyLDAvis.sklearn.prepare(model, tf, tf_vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This still prioritises programming language keywords. One approach to solving this problem is to consider all keywords as \"stopwords\". First, gather a list of R, Python and Javascript keywords:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keyword\n",
    "\n",
    "python_keywords = keyword.kwlist\n",
    "python_keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R reserved words (sourced from the manual: https://stat.ethz.ch/R-manual/R-devel/library/base/html/Reserved.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_keywords = [\n",
    "    \"if\", \n",
    "    \"else\", \n",
    "    \"repeat\",\n",
    "    \"while\",\n",
    "    \"function\", \n",
    "    \"for\",\n",
    "    \"in\",\n",
    "    \"next\",\n",
    "    \"break\",\n",
    "    \"TRUE\",\n",
    "    \"FALSE\",\n",
    "    \"NULL\", \n",
    "    \"Inf\", \n",
    "    \"NaN\",\n",
    "    \"NA\",\n",
    "    \"NA_integer_\",\n",
    "    \"NA_real_\",\n",
    "    \"NA_complex_\",\n",
    "    \"NA_character_\", \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Javascript keywords and reserved words (source: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Lexical_grammar#Keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "javascript_keywords = [  # jaccard(\"ideal javascript topic\", topic_i)\n",
    "    \"break\",\n",
    "    \"case\",\n",
    "    \"catch\",\n",
    "    \"class\",\n",
    "    \"const\",\n",
    "    \"continue\",\n",
    "    \"debugger\",\n",
    "    \"default\",\n",
    "    \"delete\",\n",
    "    \"do\",\n",
    "    \"else\",\n",
    "    \"export\",\n",
    "    \"extends\",\n",
    "    \"finally\",\n",
    "    \"for\",\n",
    "    \"function\",\n",
    "    \"if\",\n",
    "    \"import\",\n",
    "    \"in\",\n",
    "    \"instanceof\",\n",
    "    \"new\",\n",
    "    \"return\",\n",
    "    \"super\",\n",
    "    \"switch\",\n",
    "    \"this\",\n",
    "    \"throw\",\n",
    "    \"try\",\n",
    "    \"typeof\",\n",
    "    \"var\",\n",
    "    \"void\",\n",
    "    \"while\",\n",
    "    \"with\",\n",
    "    \"yield\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = minimal_dataset['documents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_vectorizer = TfidfVectorizer(stop_words=javascript_keywords+python_keywords+r_keywords)\n",
    "tf = tf_vectorizer.fit_transform(documents)\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "    \n",
    "with open('../data/tfidf_lda_tf_ignore_keywords.pickle', 'rb') as f:\n",
    "    pickle.dump(tf, f)\n",
    "    \n",
    "with open('../data/tfidf_lda_tf_vectoriser_ignore_keywords.pickle', 'rb') as f:\n",
    "    pickle.dump(tf_vectoriser, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have four programming languages, try to use LDA to determine these four programming languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "number_of_themes = 3\n",
    "\n",
    "lda = LatentDirichletAllocation(n_topics=number_of_themes,  n_jobs=1)\n",
    "model = lda.fit(tf)\n",
    "\n",
    "with open('../data/tfidf_lda_model_ignore_keywords.pickle', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/tfidf_lda_model_ignore_keywords.pickle', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "    \n",
    "with open('../data/tfidf_lda_tf_ignore_keywords.pickle', 'rb') as f:\n",
    "    tf = pickle.load(f)\n",
    "    \n",
    "with open('../data/tfidf_lda_tf_vectoriser_ignore_keywords.pickle', 'rb') as f:\n",
    "    tf_vectoriser = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pyLDAvis.sklearn.prepare(model, tf, tf_vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring the Efficacy of Topic Models (WRITEUP: WHO?)\n",
    "\n",
    "Main question: How do we evaluate how well a topic (from LDA for example) represents a meaningful \"topic\" or theme?\n",
    "\n",
    "TODO: do some research on this??? There must be some papers etc that try to formalise this that we can borrow ideas from?\n",
    "\n",
    "Paper dump:\n",
    "  - Looks like a good summary paper: http://www.aclweb.org/anthology/E14-4005 Find more papers from this ones references?\n",
    "    - \" KL-divergence (Li and McCallum, 2006; Wang et al., 2009; Newman et al., 2009), cosine measure (He et al., 2009; Ramage et al., 2009) and the average Log Odds Ratio (Chaney and Blei, 2012). \"\n",
    "    - \"Kim and Oh (2011) also applied  the  cosine  measure  and  KL-Divergence which were compared with four other measures: Jaccard’s Coefficient, Kendall’s τ coefficient, Discount  Cumulative  Gain  and  Jensen  Shannon  Divergence (JSD).\"\n",
    "  - Cool name haven't read it: http://papers.nips.cc/paper/3700-reading-tea-leaves-how-humans-interpret-topic-models.pdf\n",
    "  \n",
    "We considered all of these metrics, and found th Jaccard Index to be most suitable. This was primarily due to it's use of set operations, which are invariant to ordering and number of observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Tea Leaves Paper\n",
    "http://papers.nips.cc/paper/3700-reading-tea-leaves-how-humans-interpret-topic-models.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Overlap\n",
    "\n",
    "I think this is used as a baseline measure in the summary paper above (http://www.aclweb.org/anthology/E14-4005). Should be a quick implementation so worth a try."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jaccard Index\n",
    "\n",
    "From the papers above this seems to have been used relatively often for _linking machine-generated topics to human topics_ and so maybe this is a good application for it. Apparently explored here \"https://link.springer.com/chapter/10.1007/978-3-642-19437-5_13\" but I haven't read it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_index(a, b):\n",
    "    a = set(a)\n",
    "    b = set(b)\n",
    "    return len(a & b) / len(a | b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the group of language keywords as the best possible topic for each language. Compare each of our machine generated topics with each of our ideal topics by computing their Jaccard Index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_vectorizer = CountVectorizer(stop_words=None)\n",
    "tf = tf_vectorizer.fit_transform(documents)\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tf_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(enumerate(model.components_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kendall’s τ Coefficient\n",
    "\n",
    "Measures the association between two ranked lists. Source: Computational Linguistics and Intelligent Text Processing book."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Topic Models\n",
    "TODO: better title needed\n",
    "\n",
    "Idea:\n",
    "  - save the actual % of each program langauge per repo\n",
    "  - Then try to use LDA model to tell us \"I believe repo <x> is 10% Topic 1, 20% Topic 2 etc\". \n",
    "  - Use analysis from above two sections to create a \"most likely mapping from lda topic to programming language\".\n",
    "  - rate our models\n",
    "\n",
    "Here we can do cross-validation etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
